<% \set QUIET 1 %>
<!DOCTYPE html>
<html><meta charset="utf-8" />
<style>
table, th, td { border: 1px solid black; border-collapse: collapse; padding: 2px 4px 2px 4px;}
th {background-color: #d2f2ff;cursor: pointer; }
tr:nth-child(even) {background-color: #eef8ff}
tr:hover { background-color: #FFFFCA}
h2 { scroll-margin-left: 2em;} /*keep the scroll left*/
caption { font-size: larger }
ol { width: fit-content;}
.warn { font-weight:bold; background-color: #FAA }
.high { border: 5px solid red;font-weight:bold}
.lime { font-weight:bold}
.lineblk {float: left; margin:0 9px 4px 0 }
.bottomright { position: fixed; right: 0px; bottom: 0px; padding: 5px; border : 2px solid #AFAFFF; border-radius: 5px;}
.thidden tr td:nth-child(2), .thidden th:nth-child(2) {display: none;}
.thidden tr td:first-child {color:blue;}
#cur { font: 5em arial; position: absolute; color:brown; animation: vanish 0.8s ease forwards; }  /*sort indicator*/
#dtls,#finditem {position: absolute;background-color:#FAFFEA;border: 2px solid blue; border-radius: 5px; padding: 1em; box-shadow: 2px 2px grey;}
@keyframes vanish { from { opacity: 1;} to {opacity: 0;} }
summary {  padding: 1rem; font: bold 1.2em arial;  cursor: pointer } 
footer { text-align: center; padding: 3px; background-color:#d2f2ff}
</style>
<% \H
\pset footer off 
SET max_parallel_workers_per_gather = 0;
%>
<h1>
  <svg width="10em" viewBox="0 0 140 80">
    <path fill="none" stroke="#000000" stroke-linecap="round" stroke-width="2"  d="m 21.2,46.7 c 1,2 0.67,4 -0.3,5.1 c -1.1,1 -2,1.5 -4,1 c -10,-3 -4,-25 -4 -25 c 0.6,-10 8,-9 8 -9 s 7,-4.5 11,0.2 c 1.2,1.4 1.7,3.3 1.7,5.17 c -0.1,3 3,7 -2,10 c-2,2 -1,5 -8,5.5 m -2 -12 c 0,0 -1,1 -0.2,0.2 m -4 12 c 0,0 0,10 -12,11"/>
    <text x="30" y="50" style="font:25px arial">gGather</text>
    <text x="60" y="62" style="fill:red; font:15px arial">Report</text>
   </svg>
   <b id="busy" class="warn"> Loading... </b>
</h1>
<% \pset tableattr 'class="lineblk"'
SELECT (SELECT count(*) > 1 FROM pg_srvr WHERE connstr ilike 'You%') AS conlines \gset
\if :conlines
  \echo "There is serious problem with the data. Please make sure that all tables are dropped and recreated as part of importing data (gather_schema.sql) and there was no error"
  "SOMETHING WENT WRONG WHILE IMPORTING THE DATA. PLEASE MAKE SURE THAT ALL TABLES ARE DROPPED AND RECREATED AS PART OF IMPORTING";
  \q
\endif
\set tzone `echo "$PG_GATHER_TIMEZONE"`
SELECT * FROM 
(WITH TZ AS (SELECT CASE WHEN :'tzone' = ''
    THEN (SELECT set_config('timezone',setting,false) FROM pg_get_confs WHERE name='log_timezone')
    ELSE  set_config('timezone',:'tzone',false) 
  END AS val)
SELECT  UNNEST(ARRAY ['Collected At','Collected By','PG build', 'PG Start','In recovery?','Client','Server','Last Reload','Current LSN']) AS pg_gather,
        UNNEST(ARRAY [CONCAT(collect_ts::text,' (',TZ.val,')'),usr,ver, pg_start_ts::text ||' ('|| collect_ts-pg_start_ts || ')',recovery::text,client::text,server::text,reload_ts::text,current_wal::text]) AS "Report-v18"
FROM pg_gather LEFT JOIN TZ ON TRUE 
UNION
SELECT  'Connection', replace(connstr,'You are connected to ','') FROM pg_srvr ) a WHERE "Report-v18" IS NOT NULL ORDER BY 1;
\pset tableattr 'id="dbs" class="thidden"'
WITH cts AS (SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) AS c_ts FROM pg_gather)
SELECT datname "DB Name",to_jsonb(ROW(tup_inserted/days,tup_updated/days,tup_deleted/days,to_char(stats_reset,'YYYY-MM-DD HH24-MI-SS')))
,xact_commit/days "Avg.Commits",xact_rollback/days "Avg.Rollbacks",(tup_inserted+tup_updated+tup_deleted)/days "Avg.DMLs", CASE WHEN blks_fetch > 0 THEN blks_hit*100/blks_fetch ELSE NULL END  "Cache hit ratio"
,temp_files/days "Avg.Temp Files",temp_bytes/days "Avg.Temp Bytes",db_size "DB size",age "Age"
FROM pg_get_db LEFT JOIN LATERAL (SELECT GREATEST((EXTRACT(epoch FROM(c_ts-stats_reset))/86400)::bigint,1) as days FROM cts) AS lat1 ON TRUE;
\pset tableattr off
%>
<div>
<details style="clear: left; width: fit-content;">
  <summary>Tune PostgreSQL Parameters (beta)</summary>
  <label for="cpus">CPUs:
  <input type="number" id="cpus" name="cpus" value="0">
  </label>
  <label for="mem" style="padding-left: 3em;">Memory(GB):
  <input type="number" id="mem" name="mem" value="0">
 </label>
 <p style="border: 2px solid blue; border-radius: 5px; padding: 1em;">Please input the CPU and Memory available on the host machine for evaluating the current parameter settings<br />
  Please see the tooltip against Parameters for recommendations based on calculations. Please seek expert advice</p>
</details>
</div>
<h2 id="topics">Sections</h2>
<ol>
<li><a href="#tables">Tables</a></li>
<li><a href="#indexes">Indexes</a></li>
<li><a href="#parameters">Parameters / Settings</a></li>
<li><a href="#extensions">Extensions</a></li>
<li><a href="#activiy">Sessions Summary</a></li>
<li><a href="#time">Database Time</a></li>
<li><a href="#sess">Session Details</a></li>
<li><a href="#blocking">Blocking Sessions</a></li>
<li><a href="#statements" title="pg_get_statements">Top 10 Statements</a></li>
<li><a href="#replstat">Replications</a></li>
<li><a href="#bgcp" >BGWriter & Checkpointer</a></li>
<li><a href="#findings">Findings</a></li>
</ol>
<div class="bottomright">
  <a href="#topics">Sections (Alt+I)</a>
</div>
<div id="sections" style="display:none">
<h2 id="tables">Tables</h2>
<p><b>NOTE : Rel size</b> is the  main fork size, <b>Tot.Tab size</b> includes all forks and toast, <b>Tab+Ind size</b> is tot_tab_size + all indexes, *Bloat estimates are indicative numbers and they can be inaccurate<br />
Objects other than tables will be marked with their relkind in brackets</p>
<% \pset footer on
\pset tableattr 'id="tabInfo" class="thidden"'%>
<% SELECT c.relname || CASE WHEN c.relkind != 'r' THEN ' ('||c.relkind||')' ELSE '' END "Name" ,
to_jsonb(ROW(r.n_tup_ins,r.n_tup_upd,r.n_tup_del,r.n_tup_hot_upd)),r.relnamespace "NS", CASE WHEN r.blks > 999 AND r.blks > tb.est_pages THEN (r.blks-tb.est_pages)*100/r.blks||'%' ELSE '' END "Bloat*",
r.n_live_tup "Live tup",r.n_dead_tup "Dead tup", CASE WHEN r.n_live_tup <> 0 THEN  ROUND((r.n_dead_tup::real/r.n_live_tup::real)::numeric,4) END "Dead/Live",
r.rel_size "Rel size",r.tot_tab_size "Tot.Tab size",r.tab_ind_size "Tab+Ind size",r.rel_age,to_char(r.last_vac,'YYYY-MM-DD HH24:MI:SS') "Last vacuum",to_char(r.last_anlyze,'YYYY-MM-DD HH24:MI:SS') "Last analyze",r.vac_nos,
ct.relname "Toast name",rt.tab_ind_size "Toast+Ind" ,rt.rel_age "Toast Age",GREATEST(r.rel_age,rt.rel_age) "Max age"
FROM pg_get_rel r
JOIN pg_get_class c ON r.relid = c.reloid AND c.relkind NOT IN ('t','p')
LEFT JOIN pg_get_toast t ON r.relid = t.relid
LEFT JOIN pg_get_class ct ON t.toastid = ct.reloid
LEFT JOIN pg_get_rel rt ON rt.relid = t.toastid
LEFT JOIN pg_tab_bloat tb ON r.relid = tb.table_oid
LEFT JOIN pg_get_ns ns ON r.relnamespace = ns.nsoid
ORDER BY r.tab_ind_size DESC LIMIT 10000; %>
<% \pset tableattr%>
<h2 id="indexes">Indexes</h2>
<% \pset tableattr 'id="IndInfo"'
SELECT ct.relname AS "Table", ci.relname as "Index",indisunique as "UK?",indisprimary as "PK?",numscans as "Scans",size
  FROM pg_get_index i 
  JOIN pg_get_class ct on i.indrelid = ct.reloid and ct.relkind != 't'
  JOIN pg_get_class ci ON i.indexrelid = ci.reloid
ORDER BY size DESC LIMIT 10000;
\pset tableattr %>
<h2 id="parameters">Parameters & settings</h2>
<% \pset tableattr 'id="params"'%>
<% SELECT coalesce(s.name,f.name) "Name",s.setting,s.unit,s.source, 
string_agg(f.sourcefile ||' - '|| f.setting || CASE WHEN f.applied = true THEN ' (applicable)' ELSE '' END ,chr(10)) FILTER (WHERE s.source != f.sourcefile OR s.source IS NULL ) AS "Other locations"
FROM pg_get_confs s FULL OUTER JOIN pg_get_file_confs f ON lower(s.name) = lower(f.name)
GROUP BY 1,2,3,4 ORDER BY 1; %>
<% \pset tableattr%>
<h2 id="extensions">Extensions</h2>
<% SELECT ext.oid,extname,rolname as owner,extnamespace,extrelocatable,extversion FROM pg_get_extension ext
JOIN pg_get_roles on extowner=pg_get_roles.oid; %>
<h2 id="activiy">Session Summary</h2>
<% \pset footer off
\pset tableattr 'id="tblss"'
 SELECT d.datname,state,COUNT(pid) 
  FROM pg_get_activity a LEFT JOIN pg_get_db d on a.datid = d.datid
    WHERE state is not null GROUP BY 1,2 ORDER BY 1; %>
<h2 id="time">Database time</h2>
<% \pset tableattr 'id="tableConten" name="waits"'
\C 'Wait Events and CPU info.'
SELECT COALESCE(wait_event,'CPU') "Event", count(*)::text FROM pg_pid_wait GROUP BY 1 ORDER BY count(*) DESC;
\C
%>
<a href="https://github.com/jobinau/pg_gather/blob/main/docs/waitevents.md">Wait Event Reference</a>
<h2 id="sess" style="clear: both">Session Details</h2>
<% \pset tableattr 'id="tblsess"' 
SELECT * FROM (
  WITH w AS (SELECT pid,COALESCE(wait_event,'CPU') wait_event,count(*) cnt FROM pg_pid_wait GROUP BY 1,2 ORDER BY 1,2),
  g AS (SELECT MAX(state_change) as ts,MAX(GREATEST(backend_xid::text::bigint,backend_xmin::text::bigint)) mx_xid FROM pg_get_activity)
  SELECT a.pid,a.state, CASE query WHEN '' THEN '**'||backend_type||' process**' ELSE left(query,60) END "Last statement", g.ts - backend_start "Connection Since", g.ts - xact_start "Transaction Since", g.mx_xid - backend_xmin::text::bigint "xmin age",
   g.ts - query_start "Statement since",g.ts - state_change "State since", string_agg( w.wait_event ||':'|| w.cnt,',') waits 
  FROM pg_get_activity a 
   LEFT JOIN w ON a.pid = w.pid
   LEFT JOIN (SELECT pid,sum(cnt) tot FROM w GROUP BY 1) s ON a.pid = s.pid
   LEFT JOIN g ON true
  WHERE a.state IS NOT NULL
  GROUP BY 1,2,3,4,5,6,7,8 ORDER BY 6 DESC NULLS LAST) AS sess
WHERE waits IS NOT NULL OR state != 'idle'; %>
<h2 id="blocking" style="clear: both">Blocking Sessions</h2>
<% \pset tableattr 'id="tblblk"'
SELECT * FROM pg_get_block; %>
<h2 id="statements" style="clear: both">Top 10 Statements</h2>
<% \pset tableattr 'id="tblstmnt"'
\C 'Statements consuming highest database time. Consider information from pg_get_statements for other criteria'
select query,total_time,calls from pg_get_statements order by 2 desc limit 10; 
\C %>
<h2 id="replstat" style="clear: both">Replication Status</h2>
<% \pset tableattr 'id="tblreplstat"'
WITH M AS (SELECT GREATEST((SELECT(current_wal) FROM pg_gather),(SELECT MAX(sent_lsn) FROM pg_replication_stat))),
  g AS (SELECT MAX(GREATEST(backend_xid::text::bigint,backend_xmin::text::bigint)) mx_xid FROM pg_get_activity)
SELECT usename AS "Replication User",client_addr AS "Replica Address",pid,state,
 pg_wal_lsn_diff(M.greatest, sent_lsn) "Transmission Lag (Bytes)",pg_wal_lsn_diff(sent_lsn,write_lsn) "Replica Write lag(Bytes)",
 pg_wal_lsn_diff(write_lsn,flush_lsn) "Replica Flush lag(Bytes)",pg_wal_lsn_diff(flush_lsn,replay_lsn) "Replay at Replica lag(Bytes)",
 slot_name "Slot",plugin,slot_type "Type",datname "DB name",temporary,active,GREATEST(g.mx_xid-old_xmin::text::bigint,0) as "xmin age",
 GREATEST(g.mx_xid-catalog_xmin::text::bigint,0) as "catalog xmin age", GREATEST(pg_wal_lsn_diff(M.greatest,restart_lsn),0) as "Restart LSN lag(Bytes)",
 GREATEST(pg_wal_lsn_diff(M.greatest,confirmed_flush_lsn),0) as "Confirmed LSN lag(Bytes)"
FROM pg_replication_stat JOIN M ON TRUE
  FULL OUTER JOIN pg_get_slots s ON pid = active_pid
  LEFT JOIN g ON TRUE
  LEFT JOIN pg_get_db ON s.datoid = datid;
%>
<h2 id="bgcp" style="clear: both">Background Writer and Checkpointer Information</h2>
<p>Efficiency of Background writer and Checkpointer Process</p>
<% \pset tableattr 'id="tblchkpnt"'
SELECT round(checkpoints_req*100/tot_cp,1) "Forced Checkpoint %" ,
round(min_since_reset/tot_cp,2) "avg mins between CP",
round(checkpoint_write_time::numeric/(tot_cp*1000),4) "Avg CP write time (s)",
round(checkpoint_sync_time::numeric/(tot_cp*1000),4)  "Avg CP sync time (s)",
round(total_buffers::numeric*8192/(1024*1024),2) "Tot MB Written",
round((buffers_checkpoint::numeric/tot_cp)*8192/(1024*1024),4) "MB per CP",
round(buffers_checkpoint::numeric*8192/(min_since_reset*60*1024*1024),4) "Checkpoint MBps",
round(buffers_clean::numeric*8192/(min_since_reset*60*1024*1024),4) "Bgwriter MBps",
round(buffers_backend::numeric*8192/(min_since_reset*60*1024*1024),4) "Backend MBps",
round(total_buffers::numeric*8192/(min_since_reset*60*1024*1024),4) "Total MBps",
round(buffers_alloc::numeric/total_buffers,3)  "New buffers ratio",
round(100.0*buffers_checkpoint/total_buffers,1)  "Clean by checkpoints (%)",
round(100.0*buffers_clean/total_buffers,1)   "Clean by bgwriter (%)",
round(100.0*buffers_backend/total_buffers,1)  "Clean by backends (%)",
round(100.0*maxwritten_clean/(min_since_reset*60000 / delay.setting::numeric),2)   "Bgwriter halts (%) per runs (**1)",
coalesce(round(100.0*maxwritten_clean/(nullif(buffers_clean,0)/ lru.setting::numeric),2),0)  "Bgwriter halt (%) due to LRU hit (**2)",
round(min_since_reset/(60*24),1) "Reset days"
FROM pg_get_bgwriter
CROSS JOIN 
(SELECT 
    round(extract('epoch' from (select collect_ts from pg_gather) - stats_reset)/60)::numeric min_since_reset,
    GREATEST(buffers_checkpoint + buffers_clean + buffers_backend,1) total_buffers,
    checkpoints_timed+checkpoints_req tot_cp 
    FROM pg_get_bgwriter) AS bg
LEFT JOIN pg_get_confs delay ON delay.name = 'bgwriter_delay'
LEFT JOIN pg_get_confs lru ON lru.name = 'bgwriter_lru_maxpages'; %>
<p>**1 What percentage of bgwriter runs results in a halt, **2 What percentage of bgwriter halts are due to hitting on <code>bgwriter_lru_maxpages</code> limit</p>
<h2 id="findings" >Findings</h2>
<ol id="finditem" style="padding:2em;position:relative">
<% \pset format aligned
\pset tuples_only on
WITH W AS (SELECT COUNT(*) AS val FROM pg_get_activity WHERE state='idle in transaction')
SELECT CASE WHEN val > 0 
  THEN '<li>There are '||val||' idle in transaction session(s) </li>' 
  ELSE NULL END 
FROM W; 
WITH W AS (SELECT count(*) AS val from pg_get_rel r JOIN pg_get_class c ON r.relid = c.reloid AND c.relkind NOT IN ('t','p'))
SELECT CASE WHEN val > 10000
  THEN '<li>There are <b>'||val||' tables!</b> in this database, Only the biggest 10000 will be listed in this report under <a href= "#tabInfo" >Tables Info</a>. Please use query No. 10. from the analysis_quries.sql for full details </li>'
  ELSE NULL END
FROM W;
WITH W AS (select last_failed_time,last_archived_time,last_archived_wal from pg_archiver_stat where last_archived_time < last_failed_time)
SELECT CASE WHEN last_archived_time IS NOT NULL
  THEN '<li>WAL archiving is failing since <b>'||last_archived_time||' (duration:'|| (SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) AS c_ts FROM pg_gather) - last_archived_time  ||') onwards</b> '  ||
  COALESCE(
  (SELECT ' With estimated size <b>' ||
  pg_size_pretty(((('x'||lpad(split_part(current_wal::TEXT,'/', 1),8,'0'))::bit(32)::bigint - ('x'||substring(last_archived_wal,9,8))::bit(32)::bigint) * 255 * 16^6 + 
  ('x'||lpad(split_part(current_wal::TEXT,'/', 2),8,'0'))::bit(32)::bigint - ('x'||substring(last_archived_wal,17,8))::bit(32)::bigint*16^6 )::bigint)
  FROM pg_gather), ' ') || '</b> behind </li>'
ELSE NULL END
FROM W;
WITH W AS (select count(*) AS val from pg_get_index i join pg_get_class ct on i.indrelid = ct.reloid and ct.relkind != 't')
SELECT CASE WHEN val > 10000
  THEN '<li>There are <b>'||val||' indexes!</b> in this database, Only biggest 10000 will be listed in this report under <a href= "#indexes" >Index Info</a>. Please use query No. 11. from the analysis_quries.sql for full details </li>'
  ELSE NULL END
FROM W;
WITH W AS (
 select string_agg(name ||'='||setting,',') as val FROM pg_get_confs WHERE 
 name in ('block_size','max_identifier_length','max_function_args','max_index_keys','segment_size','wal_block_size') AND 
 (name,setting) NOT IN (('block_size','8192'),('max_identifier_length','63'),('max_function_args','100'),('max_index_keys','32'),('segment_size','131072'),('wal_block_size','8192'))
 OR (name = 'wal_segment_size' AND unit ='8kB' and setting != '2048') OR (name = 'wal_segment_size' AND unit ='B' and setting != '16777216')  
)
SELECT CASE WHEN LENGTH(val) > 1
  THEN '<li>Detected Non-Standard Compile-time parameter changes <b>'||val||' </b>. Custom Compilation prone to bugs and it is beyond supportability</li>'
  ELSE NULL END
FROM W;
WITH W AS (
SELECT count(*) cnt FROM pg_get_confs WHERE source IS NOT NULL )
SELECT CASE WHEN cnt < 1
  THEN '<li>Couldn''t get parameter values. Partial gather or corrupt Parameter file(s)</li>'
  ELSE NULL END
FROM W;
SELECT 'ERROR :'||error ||': '||name||' with setting '||setting||' in '||sourcefile FROM pg_get_file_confs WHERE error IS NOT NULL;
%>
</ol>
<div id="analdata" hidden>
<% \pset format unaligned
SELECT to_jsonb(r) FROM
(SELECT 
  (select recovery from pg_gather) AS clsr,
  (SELECT to_jsonb(ROW(count(*),COUNT(*) FILTER (WHERE last_vac IS NULL),COUNT(*) FILTER (WHERE last_anlyze IS NULL))) 
     from pg_get_rel r JOIN pg_get_class c ON r.relid = c.reloid AND c.relkind NOT IN ('t','p')) AS tabs,
  (SELECT to_jsonb(ROW(COUNT(*),COUNT(*) FILTER (WHERE CONN < interval '15 minutes' ) )) FROM 
    (WITH g AS (SELECT MAX(state_change) as ts FROM pg_get_activity)
    SELECT pid,g.ts - backend_start CONN
    FROM pg_get_activity
    LEFT JOIN g ON true
    WHERE EXISTS (SELECT pid FROM pg_pid_wait WHERE pid=pg_get_activity.pid)
    AND backend_type='client backend') cn) AS cn,
  (select count(*) from pg_get_class where relkind='p') as ptabs,
  (SELECT  to_jsonb(ROW(count(*) FILTER (WHERE state='active' AND state IS NOT NULL), 
   count(*) FILTER (WHERE state='idle in transaction'), count(*) FILTER (WHERE state='idle'),
   count(*) FILTER (WHERE state IS NULL), count(*) FILTER (WHERE leader_pid IS NOT NULL) , count(*)))
   FROM pg_get_activity) as sess,
  (WITH curdb AS (SELECT trim(both '\"' from substring(connstr from '\"\w*\"')) "curdb" FROM pg_srvr WHERE connstr like '%to database%'),
    cts AS (SELECT COALESCE((SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) FROM pg_gather),current_timestamp) AS c_ts)
    SELECT to_jsonb(ROW(curdb,stats_reset,c_ts,days)) FROM 
    curdb LEFT JOIN pg_get_db ON pg_get_db.datname=curdb.curdb
    LEFT JOIN LATERAL (SELECT GREATEST((EXTRACT(epoch FROM(c_ts-stats_reset))/86400)::bigint,1) as days FROM cts) AS lat1 ON TRUE
    LEFT JOIN cts ON true) as dbts,
  (SELECT json_agg(pg_get_ns) FROM  pg_get_ns WHERE nsoid > 16384 OR nsname='public') AS ns,
  (SELECT to_jsonb((collect_ts-last_failed_time) < '5 minute' :: interval) FROM pg_gather,pg_archiver_stat) AS arcfail,
  (SELECT to_jsonb(setting) FROM pg_get_confs WHERE name = 'archive_library') AS arclib
) r;
%>
</div>
</div> <!--End of "sections"-->
<footer>End of <a href="https://github.com/jobinau/pg_gather">pgGather</a> Report</footer>
<script type="text/javascript">
//Global object to hold json values passed from the SQL analysis
obj={};

//Global variable to hold autovacuum_freeze_max_age, so that each table can be compared
autovacuum_freeze_max_age = 0;
//total DB size
totdb=0;
//Number of CPUs and Memory
totCPU=0;
totMem=0;


//when the DOM is ready
document.addEventListener("DOMContentLoaded", () => {
obj=JSON.parse( document.getElementById("analdata").innerText);
checkpars();
checktabs();
checkdbs();
checkfindings();
});

window.onload = function() {
// can also use window.addEventListener('load', (event) => {
  ["tabInfo","IndInfo","params","sections"].forEach(function(t) {document.getElementById(t).style="display:table";})
  document.getElementById("sections").style="display:table";
  document.getElementById("busy").style="display:none";
};


//check the obj content and display findings messages accordingly
function checkfindings(){
  let strfind = "";
  if (obj.cn.f1 > 0){
    strfind="<li><b>" + obj.cn.f2 + " / " + obj.cn.f1 + " connections </b> in use are new. "
    if (obj.cn.f2 > 9 || obj.cn.f2/obj.cn.f1 > 0.7 ){
      strfind+="Please consider this for improving connection pooling"
    } 
    strfind += "</li>";
  }
  if (obj.ptabs > 0) strfind += "<li>"+ obj.ptabs +" Natively partitioned tables found. Tables section could contain partitions</li>";
 if(obj.clsr){
  strfind += "<li>PostgreSQL is in Standby mode or in Recovery</li>";
 }else{
  if ( obj.tabs.f2 > 0 ) strfind += "<li> <b>No vaccum info for " + obj.tabs.f2 + "</b> tables </li>";
  if ( obj.tabs.f3 > 0 ) strfind += "<li> <b>No statistics available for " + obj.tabs.f3 + " tables</b>, query planning can go wrong </li>";
  if ( obj.tabs.f1 > 10000) strfind += "<li> There are <b>" + obj.tabs.f1 + " tables</b> in the database. Only 10000 will be displayed in the report. Avoid too many tables in single database</li>";
  if (obj.arcfail) strfind += "<li>WAL archiving is suspected to be <b>failing</b>, please check PG logs</li>";
  let tempNScnt = obj.ns.filter(n => n.nsname.indexOf("pg_temp") > -1).length;
  strfind += "<li> There are <b>" + (obj.ns.length - tempNScnt).toString()  + " user schemas and " + tempNScnt + " temporary schema</b> in this database.</li>";
  document.getElementById("finditem").innerHTML += strfind;
 }
  //Add footer to database details table at the top
  var el=document.createElement("tfoot");
  el.innerHTML = "<th colspan='9'>**Averages are Per Day. Total DB size is : "+ bytesToSize(totdb) +"</th>";
  dbs=document.getElementById("dbs");
  dbs.appendChild(el);
  
  //Add footer to Sessions Summary table
  el=document.createElement("tfoot");
  el.innerHTML = "<th colspan='3'>Active: "+ obj.sess.f1 +", Idle-in-transaction: " + obj.sess.f2 + ", Idle: " + obj.sess.f3 + ", Background: " + obj.sess.f4 + ", Workers: " + obj.sess.f5 + ", Total: " + obj.sess.f6 + "</th>";
  tblss=document.getElementById("tblss");
  tblss.appendChild(el);

}

//Event listeners for changing the CPU and Memory
document.getElementById("cpus").addEventListener("change", (event) => {
  totCPU = event.target.value;
  checkpars();
});
document.getElementById("mem").addEventListener("change", (event) => {
  totMem = event.target.value;
  checkpars();
});


//Convert bytes into human readable formats
function bytesToSize(bytes,divisor = 1000) {
  const sizes = ["B","KB","MB","GB","TB"];
  if (bytes == 0) return "0B";
  const i = parseInt(Math.floor(Math.log(bytes) / Math.log(divisor)), 10);
  if (i === 0) return bytes + sizes[i];
  return (bytes / (divisor ** i)).toFixed(1) + sizes[i]; 
}

//Convert time format seperated by colon (:) to seconds for comparision
function DurationtoSeconds(duration){
    const [hours, minutes, seconds] = duration.split(":");
    return Number(hours) * 60 * 60 + Number(minutes) * 60 + Number(seconds);
};


function checkpars(){
  const startTime =new Date().getTime();
  trs=document.getElementById("params").rows
  for(var i=1;i<trs.length;i++){
    tr=trs[i]; nm=tr.cells[0]; val=tr.cells[1];
    switch(nm.innerText){
      case "archive_command" :
        if (obj.arclib !== null && obj.arclib.length > 0) { val.classList.add("warn"); val.title="archive_command won't be in-effect, because archive_library : " + obj.arclib + " is specified"  }
        break;
      case "autovacuum" :
        if(val.innerText != "on") { val.classList.add("warn"); val.title="Autovacuum must be on" }
        break;
      case "autovacuum_max_workers" :
        if(val.innerText > 3) { val.classList.add("warn"); val.title="Worker slows down as the number of workers increases" }
        break;
      case "autovacuum_vacuum_cost_limit" :
        if(val.innerText > 800 || val.innerText == -1 ) { val.classList.add("warn"); val.title="Consider a value less than 800" }
        break;
      case "autovacuum_freeze_max_age" :
        autovacuum_freeze_max_age = Number(val.innerText);
        if (autovacuum_freeze_max_age > 800000000) val.classList.add("warn");
        break;
      case "deadlock_timeout":
        val.classList.add("lime");
        break;
      case "effective_cache_size":
        val.classList.add("lime"); val.title=bytesToSize(val.innerText*8192,1024);
        break;
      case "maintenance_work_mem":
        val.classList.add("lime"); val.title=bytesToSize(val.innerText*1024,1024);
        break;
      case "work_mem":
        val.classList.add("lime"); val.title=bytesToSize(val.innerText*1024,1024);
        if(val.innerText > 98304) val.classList.add("warn");
        break;
      case "huge_pages":
        val.classList.add("lime");
        break;
      case "huge_page_size":
        val.classList.add("lime");
        break;
      case "checkpoint_timeout":
        if(val.innerText < 1200) { val.classList.add("warn"); val.title="Too small gap between checkpoints"}
        break;
      case "hot_standby_feedback":
        val.classList.add("lime");
        break;
      case "shared_buffers":
        val.classList.add("lime"); val.title=bytesToSize(val.innerText*8192,1024);
        if( totMem > 0 && ( totMem < val.innerText*8*0.2/1048576 || totMem > val.innerText*8*0.3/1048576 ))
          { val.classList.add("warn"); val.title="Approx. 25% of available memory is recommended, current value of " + bytesToSize(val.innerText*8192,1024) + " appears to be off" }
        break;
      case "max_connections":
        val.title="Avoid value exceeding 10x of the CPUs"
        if( totCPU > 0 ){
          if(val.innerText > 10 * totCPU) { val.classList.add("warn"); val.title="If there is only " + totCPU + " CPUs value above " + 10*totCPU + " Is not recommendable for performance and stability" }
          else { val.classList.remove("warn"); val.classList.add("lime"); val.title="Current value is good" }
        } else if (val.innerText > 500) val.classList.add("warn")
        else val.classList.add("lime")
        break;
      case "max_wal_size":
        val.classList.add("lime"); val.title=bytesToSize(val.innerText*1024*1024,1024);
        if(val.innerText < 10240) val.classList.add("warn");
        break;
      case "random_page_cost":
        if(val.innerText > 1.2) val.classList.add("warn");
        break;
      case "jit":
        if (val.innerText=="on") { val.classList.add("warn"); val.title="JIT is reportedly causing high memory usage and even crashes in few cases. consider disabling it unless needed" }
        break;
      case "server_version":
        val.classList.add("lime");
        break;
      case "synchronous_standby_names":
        if (val.innerText.trim().length > 0){ val.classList.add("warn"); val.title="Synchronous Standby can cause session hangs, and poor performance"; }
        break;
    }
  }
const endTime = new Date().getTime();
console.log("time taken :" + (endTime - startTime));
}

//Cells with value greater than autovacuum_freeze_max_age
function aged(cell){
 if(cell.innerHTML > autovacuum_freeze_max_age){ cell.classList.add("warn"); cell.title =  Number(cell.innerText).toLocaleString("en-US"); }
}

//Check Table Level info
function checktabs(){
  const startTime =new Date().getTime();
  const trs=document.getElementById("tabInfo").rows
  const len=trs.length;
  [10,16,17].forEach(function(num){trs[0].cells[num].title="autovacuum_freeze_max_age=" + autovacuum_freeze_max_age.toLocaleString("en-US")})
  for(var i=1;i<len;i++){
  //TODO : trs.forEach (convert the for loop to forEach if possible)
    tr=trs[i]; let TotTab=tr.cells[8]; TotTabSize=Number(TotTab.innerHTML); TabInd=tr.cells[9]; TabIndSize=(TabInd.innerHTML);
    if(TotTabSize > 5000000000 ) { TotTab.classList.add("lime"); TotTab.title = bytesToSize(TotTabSize) + "\nBig Table, Consider Partitioning, Archive+Purge"; 
    } else TotTab.title=bytesToSize(TotTabSize);
    //Tab above 20MB and with Index bigger than Tab
    if( TabIndSize > 2*TotTabSize && TotTabSize > 2000000 ){ TabInd.classList.add("warn"); TabInd.title="Indexes of : " + bytesToSize(TabIndSize-TotTabSize) + " is " + ((TabIndSize-TotTabSize)/TotTabSize).toFixed(2) + "x of Table " + bytesToSize(TotTabSize) + "\n Total : " + bytesToSize(TabIndSize)
    } else TabInd.title=bytesToSize(TabIndSize); 
    //Tab+Ind > 10GB
    if (TabIndSize > 10000000000) TabInd.classList.add("lime");
    //Check the TOAST size
    if (tr.cells[15].innerText > 10000) { 
      tr.cells[15].title=bytesToSize(Number(tr.cells[15].innerText)); 
      //if TOAST is more than 10GB
      if (tr.cells[15].innerText > 10737418240) tr.cells[15].classList.add("warn")
      else tr.cells[15].classList.add("lime")
    }
    aged(tr.cells[10]);
    aged(tr.cells[16]);
    aged(tr.cells[17]);
  }
const endTime = new Date().getTime();
console.log("time taken for checktabs :" + (endTime - startTime));
}

//Inspect database level info
function checkdbs(){
  //second column in the table is hidden, be careful
  const trs=document.getElementById("dbs").rows
  const len=trs.length;
  trs[0].cells[6].title="Average Temp generation Per Day"; trs[0].cells[7].title="Average Temp generation Per Day"; trs[0].cells[9].title="autovacuum_freeze_max_age=" + autovacuum_freeze_max_age.toLocaleString("en-US");
  for(var i=1;i<len;i++){
    tr=trs[i];
    if(obj.dbts !== null && tr.cells[0].innerHTML == obj.dbts.f1) tr.cells[0].classList.add("lime");
    [7,8].forEach(function(num) {  if (tr.cells[num].innerText > 1048576) { tr.cells[num].classList.add("lime"); tr.cells[num].title=bytesToSize(tr.cells[num].innerText) } });
    if(tr.cells[7].innerHTML > 50000000000) tr.cells[7].classList.add("warn");
    totdb=totdb+Number(tr.cells[8].innerText);
    aged(tr.cells[9]);
  }  
}

//Sort logic
const getCellValue = (tr, idx) => tr.children[idx].innerText || tr.children[idx].textContent;
const comparer = (idx, asc) => (a, b) => ((v1, v2) =>   v1 !== ''' && v2 !== ''' && !isNaN(v1) && !isNaN(v2) ? v1 - v2 : v1.toString().localeCompare(v2))(getCellValue(asc ? a : b, idx), getCellValue(asc ? b : a, idx));
document.querySelectorAll(''th'').forEach(th => th.addEventListener(''click'', (() => {
  const table = th.closest(''table'');
  th.style.cursor = "progress";
  var el=document.createElement("div");
  el.setAttribute("id", "cur");
  if (this.asc) el.textContent = "⬆";
  else el.textContent = "⬇";
  th.appendChild(el);
  setTimeout(() => { el.remove();},1000);
  setTimeout(function (){
  Array.from(table.querySelectorAll(''tr:nth-child(n+2)'')).sort(comparer(Array.from(th.parentNode.children).indexOf(th), this.asc = !this.asc)).forEach(tr => table.appendChild(tr) );
  setTimeout(function(){th.style.cursor = "pointer";},10);
  },50);
})));

/////############## Pop-up details box######################
function dbsdtls(th){
  let o=JSON.parse(th.cells[1].innerText);
  let str="";
  if(th.cells[0].classList.contains("lime")) str = "<br/>(pg_gather connected)";
  return "<b>" + th.cells[0].innerText + "</b>" + str + "<br/> Inserts per day : " + o.f1 + "<br/>Updates per day : " + o.f2 + "<br/>Deletes per day : " + o.f3 + "<br/>Stats Reset : " + o.f4 ;
}

function tabdtls(th){
  let o=JSON.parse(th.cells[1].innerText);
  let vac=th.cells[13].innerText;
//lookup cells[2] value, the oid of NS in the obj.ns json collection  
  let ns=obj.ns.find(el => el.nsoid === JSON.parse(th.cells[2].innerText).toString());
  let str=""
  if (obj.dbts.f4 < 1) obj.dbts.f4 = 1;
  if (vac > 0) str="<br />Vacuums / day : " + Number(vac/obj.dbts.f4).toFixed(1);
  str += "<br/>Inserts / day : " + Math.round(o.f1/obj.dbts.f4);
  str += "<br/>Updates / day : " + Math.round(o.f2/obj.dbts.f4);
  str += "<br/>Deletes / day : " + Math.round(o.f3/obj.dbts.f4);
  str += "<br/>HOT.updates / day : " + Math.round(o.f4/obj.dbts.f4);
  return "<b>" + th.cells[0].innerText + "</b><br/>Schema : " + ns.nsname + str;
}


//Table with hidden columns
document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("mouseover", (() => {
  th=td.parentNode;
  tab=th.closest("table");
  var el=document.createElement("div");
  el.setAttribute("id", "dtls");
  el.setAttribute("align","left");
  if(tab.id=="dbs") el.innerHTML=dbsdtls(th);
  if(tab.id=="tabInfo") el.innerHTML=tabdtls(th);
  th.cells[2].appendChild(el);
})));

document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("mouseout", (() => {
  td.parentNode.cells[2].innerHTML=td.parentNode.cells[2].firstChild.textContent;
})));
//################End of popup box at DB level ##########################


//Index analysis
trs=document.getElementById("IndInfo").rows;
for (let tr of trs) {
  if(tr.cells[4].innerText == 0) {tr.cells[4].classList.add("warn"); tr.cells[4].title="Unused Index"}
  tr.cells[5].title=bytesToSize(Number(tr.cells[5].innerText));
  if(tr.cells[5].innerText > 2000000000) tr.cells[5].classList.add("lime");
}

//database time draw graph
trs=document.getElementById("tableConten").rows;
if (trs.length > 1){ 
  maxevnt=Number(trs[1].cells[1].innerText);
  for (let tr of trs) {
  evnts=tr.cells[1];
  if (evnts.innerText*1500/maxevnt > 1) evnts.innerHTML += ''<div style="display:inline-block;width:'+ Number(evnts.innerText)*1500/maxevnt + 'px; border: 7px outset brown; border-width:7px 0; margin:0 5px;box-shadow: 2px 2px grey;">''
  }
}else {
  document.getElementById("tableConten").remove();
  document.getElementById("time").innerText="Database wait events are not found"  
}


//Prepare the list of blockers and Victims
let blokers = []
let blkvictims = []
trs=document.getElementById("tblblk").rows;
for (let tr of trs) {
  victim=tr.cells[0].innerText;
  blkr=tr.cells[9].innerText;
  if (victim > 0) blkvictims.push(victim);
  if (blkr > 0) blokers.push(blkr);
}

//Session information.
trs=document.getElementById("tblsess").rows;
for (let tr of trs){
 pid=tr.cells[0];
 xidage=tr.cells[5];
 stime=tr.cells[7];
 if(xidage.innerText > 20) xidage.classList.add("warn");
 //if pid exists in blockers list
 if (blokers.indexOf(pid.innerText) > -1){ 
     pid.classList.add("warn"); pid.title="Blocker";
     //In case the pid is not there in vicitms list, it is the first blocker
     if (blkvictims.indexOf(pid.innerText) == -1) pid.classList.add("high");
  };
  if(DurationtoSeconds(stime.innerText) > 300) stime.classList.add("warn");
}

//If blocking session section is empty
if(document.getElementById("tblblk").rows.length < 2){ 
  document.getElementById("tblblk").remove();
  document.getElementById("blocking").innerText="No Blocking Sessions Found";
}

//if there is no info from pg_stat_statements
if(document.getElementById("tblstmnt").rows.length < 2){ 
  document.getElementById("tblstmnt").remove();
  document.getElementById("statements").innerText="pg_stat_statements info is not available"
}

//Checkpointer and bgwriter info
trs=document.getElementById("tblchkpnt").rows;
if (trs.length > 1){
  tr=trs[1]
  if (tr.cells[0].innerText > 10){
    tr.cells[0].classList.add("high"); tr.cells[0].title="More than 10% of forced checkpoints is not desirable, increase max_wal_size";
  }
  if(tr.cells[1].innerText < 10 ){
    tr.cells[1].classList.add("high"); tr.cells[1].title="checkpoints are too frequent. consider checkpoint_timeout=1800";
  }
  if(tr.cells[13].innerText > 25){
    tr.cells[13].classList.add("high"); tr.cells[13].title="too many dirty pages cleaned by backends";
    if(tr.cells[12].innerText < 30){
      tr.cells[12].classList.add("high"); tr.cells[12].title="bgwriter is not efficient";
      if(tr.cells[14].innerText < 30){
        tr.cells[14].classList.add("high"); tr.cells[14].title="bgwriter could run more frequently. reduce bgwriter_delay";
      }
      if(tr.cells[15].innerText > 30){
        tr.cells[15].classList.add("high"); tr.cells[15].title="bgwriter halts too frequently. increase bgwriter_lru_maxpages";
      }
    }
  }
}

//Check Replication status
tab=document.getElementById("tblreplstat")
if (tab.rows.length > 1){
  for(var i=1;i<tab.rows.length;i++){
    row=tab.rows[i];
    [4,5,6,7,16,17].forEach(function(num){ cell=row.cells[num]; cell.title=bytesToSize(Number(cell.innerText),1024); 
     if(cell.innerText > 104857600){
      cell.classList.add("warn");
     }else{
      cell.classList.add("lime");
     }
    });
    [14,15].forEach(function(num){  if(row.cells[num].innerText > 20) row.cells[num].classList.add("warn"); });
  }
}else{
  tab.remove()
  h2=document.getElementById("replstat")
  h2.innerText="No Replication found"
}


//Press Alt_i to go to topics
document.onkeyup = function(e) {
  if (e.altKey && e.which === 73) document.getElementById("topics").scrollIntoView({behavior: "smooth"});
  //       e.preventDefault();
}
</script>
</html>
