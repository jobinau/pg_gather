<% \set QUIET 1 %>
<!DOCTYPE html>
<html><meta charset="utf-8" />
<style>
#finditem,#paramtune,table {box-shadow: 0px 20px 30px -10px grey; margin: 2em; caption {font:large bold; text-align:left; white-space: nowrap; span {font: italic bold 1.7em Georgia, serif}}}
table, th, td { border: 1px solid #6FAEBF; border-spacing: 0; padding: 4px;position: relative; } 
th {background-color: #d2f5ff;cursor: pointer; position:sticky; top:1em; border-color: #4F8E9F;z-index: 1}
tr:nth-child(even) {background-color: #eef8ff} 
c { display: block }
c:hover,li:hover { background-color: #DFD; text-shadow: #800 0.5px 0 0.5px; }
a:hover,tr:hover { background-color: #EBFFDA}
ol { width: fit-content;}
.warn { font-weight:bold; background-color: #FBA }
.high { border: 5px solid red;font-weight:bold}
.lime { font-weight:bold;background-color: #FFD}
.lineblk {float: left; margin:2em }
.thidden tr { td:nth-child(2),th:nth-child(2) {display: none} td:first-child {color:blue}}
.bar {display:inline-block; border: 7px outset brown; border-width:7px 0; margin:0 5px;box-shadow: 2px 2px grey;}  /* bar for graph */
#bottommenu { position: fixed; right: 0px; bottom: 0px; padding: 5px; border : 2px solid #AFAFFF; border-radius: 5px; z-index: 3}
#cur { font: 5em arial; position: absolute; color:brown; animation: vanish 2s ease forwards; z-index: 3 }  /*sort indicator*/
#dtls,#finditem,#paramtune,#menu { font-weight:initial;line-height:1.5em;position:absolute;background-color:#FAFFEA;border: 2px solid blue; border-radius: 5px; padding: 1em;box-shadow: 0px 20px 30px -10px grey; z-index: 2}
#dtls { left:100%; top: 4%; width: max-content; color: black;}
@keyframes vanish { from { opacity: 1;} to {opacity: 0;} }
summary {  padding: 1rem; font: bold 1.2em arial;  cursor: pointer } 
footer { text-align: center; padding: 3px; background-color:#d2f2ff}
</style>
<% \H
\pset footer off 
SET max_parallel_workers_per_gather = 0;
-- SELECT setting AS pgver FROM pg_get_confs WHERE name = 'server_version_num' \gset
SELECT min(min) AS reset_ts FROM 
(SELECT min(stats_reset) FROM pg_get_io
UNION
SELECT stats_reset FROM pg_stat_archiver
UNION
SELECT stats_reset FROM pg_get_wal
UNION
SELECT stats_reset FROM pg_get_bgwriter) a \gset
%>
<h1>
  <svg width="10em" viewBox="0 0 140 80">
    <path fill="none" stroke="#000000" stroke-linecap="round" stroke-width="2"  d="m 21.2,46.7 c 1,2 0.67,4 -0.3,5.1 c -1.1,1 -2,1.5 -4,1 c -10,-3 -4,-25 -4 -25 c 0.6,-10 8,-9 8 -9 s 7,-4.5 11,0.2 c 1.2,1.4 1.7,3.3 1.7,5.17 c -0.1,3 3,7 -2,10 c-2,2 -1,5 -8,5.5 m -2 -12 c 0,0 -1,1 -0.2,0.2 m -4 12 c 0,0 0,10 -12,11"/>
    <text x="30" y="50" style="font:25px arial">gGather</text>
    <text x="60" y="62" style="fill:red; font:15px arial">Report</text>
   </svg>
   <b id="busy" class="warn"> Loading... </b>
</h1>
<% \pset tableattr 'id="tblgather" class="lineblk"'
SELECT (SELECT count(*) > 1 FROM pg_srvr WHERE connstr ilike 'You%') AS conlines \gset
\if :conlines
  \echo "There is serious problem with the data. Please make sure that all tables are dropped and recreated as part of importing data (gather_schema.sql) and there was no error"
  "SOMETHING WENT WRONG WHILE IMPORTING THE DATA. PLEASE MAKE SURE THAT ALL TABLES ARE DROPPED AND RECREATED AS PART OF IMPORTING";
  \q
\endif
\set tzone `echo "$PG_GATHER_TIMEZONE"`
SELECT * FROM 
(WITH conf AS (SELECT CASE WHEN :'tzone' = '' THEN (SELECT setting FROM pg_get_confs WHERE name='log_timezone') ELSE :'tzone' END AS setting),
 tz AS ( SELECT set_config('timezone',COALESCE(name,'UTC'),false) AS val FROM conf LEFT JOIN pg_timezone_names  ON pg_timezone_names.name = conf.setting)
SELECT  UNNEST(ARRAY ['Collected At','Collected By','PG build', 'Last Startup','In recovery?','Client','Server','Last Reload','Latest xid','Oldest xid ref','Current LSN','Time Line','WAL file','System']) AS pg_gather,
        UNNEST(ARRAY [CONCAT(collect_ts::text,' (',TZ.val,')'),usr,ver, pg_start_ts::text ||' ('|| collect_ts-pg_start_ts || ')',recovery::text,client::text,server::text,reload_ts::text || ' ('|| collect_ts-reload_ts || ')',
        pg_snapshot_xmax(snapshot)::text,pg_snapshot_xmin(snapshot)::text,current_wal::text,timeline::text || ' (Hex:' ||  upper(to_hex(timeline)) || ')',  lpad(upper(to_hex(timeline)),8,'0')||substring(pg_walfile_name(current_wal) from 9 for 16),
        'ID: ' || systemid || ' Since: ' || to_timestamp ( systemid >> 32 ) || ' ('|| collect_ts-to_timestamp ( systemid >> 32 ) || ')']) AS "Report"
FROM pg_gather LEFT JOIN tz ON TRUE 
UNION
SELECT  'Connection', replace(connstr,'You are connected to ','') FROM pg_srvr ) a WHERE "Report" IS NOT NULL ORDER BY 1;
\pset tableattr 'id="dbs" class="thidden"'
\C ''
WITH cts AS (SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) AS c_ts FROM pg_gather)
SELECT datname "DB Name",concat(tup_inserted/days,',',tup_updated/days,',',tup_deleted/days,',',to_char(COALESCE(pg_get_db.stats_reset,:'reset_ts'),'YYYY-MM-DD HH24-MI-SS'),',',datid,',',mxidage,',',encod,',',colat)
,xact_commit/days "Avg.Commits",xact_rollback/days "Avg.Rollbacks",(tup_inserted+tup_updated+tup_deleted)/days "Avg.DMLs", CASE WHEN blks_fetch > 0 THEN blks_hit*100/blks_fetch ELSE NULL END  "Cache hit ratio"
,temp_files/days "Avg.Temp Files",temp_bytes/days "Avg.Temp Bytes",db_size "DB size",age "Age"
FROM pg_get_db
LEFT JOIN LATERAL (SELECT GREATEST((EXTRACT(epoch FROM(c_ts-COALESCE(pg_get_db.stats_reset, :'reset_ts')))/86400)::bigint,1) as days FROM cts) AS lat1 ON TRUE;
\pset tableattr off
%>
<div id="paramrecs">
<details style="clear: left; border: 2px solid #b3aeae; border-radius: 5px; padding: 1em;margin: 2em;">
  <summary style="font: italic bold 2em Georgia">Parameter Recommendations</summary>
  <fieldset style="border: 2px solid blue; border-radius: 5px; padding: 1em; width: fit-content;">
  <legend>Inputs</legend>
  <label for="cpus">CPUs:
  <input type="number" id="cpus" name="cpus" value="4">
  </label>
  <label for="mem" style="padding-left: 3em;">Memory(GB):
  <input type="number" id="mem" name="mem" value="8">
 </label>
 <label for="strg" style="padding-left: 3em;"> Storage:
  <select id="strg" name="strg">
    <option value="ssd">SSD/NVMe</option>
    <option value="san">SAN</option>
    <option value="mag">Magnetic</option>
   </select>
 </label>
 <label for="wrkld" style="padding-left: 3em;"> Work load:
  <select id="wrkld" name="wrkld">
    <option value="oltp">OLTP</option>
    <option value="olap">OLAP/DSS</option>
    <option value="mixed">Mixed</option>
   </select>
 </label>
 <label for="flsys" style="padding-left: 3em;"> Filesystem:
  <select id="flsys" name="flsys">
    <option value="rglr">Regular (like: ext4/xfs)</option>
    <option value="cow">COW (like: zfs/btrfs)</option>
   </select>
 </label>
 <p>☛ Please provide the CPU and memory available on the host machine. Choose the most suitable options from the list to receive specific recommendations. If you are unsure, seek expert guidance.</p>
</fieldset>
  <div id="paramtune" style="padding:2em;position:relative;width: fit-content;">
   <h3 style="font: italic 1.2em Georgia, serif;text-decoration: underline; margin: 0 0 0.5em;">Recommendations:</h3>
  <ol>
  </ol>
  <p>* Collecting pg_gather data during right utilization levels is important to tune the system for the specific workload</p>
</div>
  <button type="button" onclick="getreccomendation()" title="Calculate / Recalculate Parameters">&#128257; Calculate</button>
  <button type="button" onclick="copyashtml()" title="Copy as html tags">Copy as HTML tags</button>
  <button type="button" onclick="copyrichhtml()" title="Copy as Rich HTML">Copy as Rich HTML</button>
</details>
</div>
<h2 id="topics">Sections</h2>
<ol>
<li><a href="#tabInfo">Tables</a></li>
<li><a href="#tabPart">Partitioned Tables</a></li>
<li><a href="#IndInfo">Indexes</a></li>
<li><a href="#params">Parameters / Settings</a></li>
<li><a href="#tblextn">Extensions</a></li>
<li><a href="#tblhba">Security-HBA rules</a>
<li><a href="#tblcs">Connection & Users</a></li>
<li><a href="#tableConten">Database Time</a></li>
<li><a href="#tblsess">Session Details</a></li>
<li><a href="#tblstmnt">Top Statements</a></li>
<li><a href="#tblreplstat">Replications</a></li>
<li><a href="#tblchkpnt" >BGWriter & Checkpointer</a></li>
<li><a href="#finditem">Findings</a></li>
</ol>
<div id="bottommenu">
 <a href="#topics" title="Sections">☰ Section Index (Alt+I)</a>
 <div id="menu" style="display:none; position: relative">
  <ol>
    <li><a href="#tblgather">Head Info</a></li>
    <li><a href="#paramrecs">Parameter Recommendations</a></li>
    <li><a href="#tabInfo">Tables</a></li>
    <li><a href="#tabPart">Partitioned Tables</a></li>
    <li><a href="#IndInfo">Indexes</a></li>
    <li><a href="#params">Parameters / Settings</a></li>
    <li><a href="#tblextn">Extensions</a></li>
    <li><a href="#tblhba">Security-HBA rules</a>
    <li><a href="#tblcs">Connection & Users</a></li>
    <li><a href="#tableConten">Database Time</a></li>
    <li><a href="#tblsess">Session Details</a></li>
    <li><a href="#tblstmnt">Top Statements</a></li>
    <li><a href="#tblreplstat">Replications</a></li>
    <li><a href="#tblchkpnt" >BGWriter & Checkpointer</a></li>
    <li><a href="#tbliostat">IO Statistics</a></li>
    <li><a href="#finditem">Findings</a></li>
  </ol>
 </div>
</div>
<div id="sections" style="display:none">
<% \pset footer on
\pset tableattr 'id="tabInfo" class="thidden"'
SELECT c.relname || CASE WHEN inh.inhrelid IS NOT NULL THEN ' (part)' WHEN c.relkind != 'r' THEN ' ('||c.relkind||')' ELSE '' END "Name" ,
concat(r.relid,',',r.n_tup_ins,',',r.n_tup_upd,',',r.n_tup_del,',',r.n_tup_hot_upd,',',isum.totind,',',isum.ind0scan,',',isum.pk,',',isum.uk,',',inhp.relname,',',inhp.relkind,',',c.relfilenode,',',c.reltablespace,',',c.reloptions),r.relnamespace "NS", CASE WHEN r.blks > 999 AND r.blks > tb.est_pages THEN (r.blks-tb.est_pages)*100/r.blks ELSE NULL END "Bloat%",
r.n_live_tup "Live",r.n_dead_tup "Dead", CASE WHEN r.n_live_tup <> 0 THEN  ROUND((r.n_dead_tup::real/r.n_live_tup::real)::numeric,1) END "D/L",
r.rel_size "Rel size",r.tot_tab_size "Tot.Tab size",r.tab_ind_size "Tab+Ind size",r.rel_age "Rel. Age",to_char(r.last_vac,'YYYY-MM-DD HH24:MI:SS') "Last vacuum",to_char(r.last_anlyze,'YYYY-MM-DD HH24:MI:SS') "Last analyze",r.vac_nos "Vaccs",
ct.relname "Toast name",rt.tab_ind_size "Toast + Ind" ,rt.rel_age "Toast Age",GREATEST(r.rel_age,rt.rel_age) "Max age",
c.blocks_fetched "Fetch",c.blocks_hit*100/nullif(c.blocks_fetched,0) "C.Hit%",to_char(r.lastuse,'YYYY-MM-DD HH24:MI:SS') "Last Use"
FROM pg_get_rel r
JOIN pg_get_class c ON r.relid = c.reloid AND c.relkind NOT IN ('t','p')
LEFT JOIN pg_get_toast t ON r.relid = t.relid
LEFT JOIN pg_get_class ct ON t.toastid = ct.reloid
LEFT JOIN pg_get_rel rt ON rt.relid = t.toastid
LEFT JOIN pg_tab_bloat tb ON r.relid = tb.table_oid
LEFT JOIN pg_get_inherits inh ON r.relid = inh.inhrelid
LEFT JOIN pg_get_class inhp ON inh.inhparent = inhp.reloid
LEFT JOIN (SELECT count(indexrelid) totind,count(indexrelid)FILTER( WHERE numscans=0 ) ind0scan, count(indexrelid) FILTER (WHERE indisprimary) pk,  
   count(indexrelid) FILTER (WHERE indisunique) uk, indrelid FROM pg_get_index GROUP BY indrelid ) AS isum ON isum.indrelid = r.relid
ORDER BY r.tab_ind_size DESC LIMIT 10000;

\pset tableattr 'id="tabPart" class="thidden"'
WITH ptables AS ( SELECT p.relname , p.relkind, i.inhparent, i.inhrelid
FROM pg_get_class p LEFT JOIN pg_get_inherits i ON i.inhparent = p.reloid
WHERE p.relkind in ('p','r'))
SELECT  p.relname "Partitioned Table", CONCAT(any_value(c.relname) FILTER (WHERE dpart = 't'),',',any_value(r.n_live_tup) FILTER (WHERE dpart='t')) "Default Partition Name, Count",
 'Native-Declarative' "Partitioning Type",  count(r.relid) "Partitions", sum(r.tot_tab_size) "tot_tab_size" , sum(r.tab_ind_size) "tab_ind_size",
  round(max(c.blocks_fetched)/sum(NULLIF(c.blocks_fetched,0))*100 ,1) "Fetch Prune %" 
FROM ptables p LEFT JOIN pg_get_rel r ON p.inhrelid = r.relid 
 LEFT JOIN pg_get_class c ON p.inhrelid = c.reloid
WHERE p.relkind = 'p' GROUP BY 1
UNION ALL
SELECT  p.relname ,',', 'Inheritance' , count(r.relid) "Partitions", sum(r.tot_tab_size) ,
  sum(r.tab_ind_size), max(c.blocks_fetched)/sum(NULLIF(c.blocks_fetched,0))*100
FROM ptables p JOIN pg_get_rel r ON p.inhrelid = r.relid
 JOIN pg_get_class c ON p.inhrelid = c.reloid
WHERE p.relkind = 'r' GROUP BY 1;

\pset tableattr 'id="IndInfo"'
SELECT n.nsname "Schema",ct.relname AS "Table", ci.relname as "Index",indisunique as "UK?",indisprimary as "PK?",numscans as "Scans",size,ci.blocks_fetched "Fetch",ci.blocks_hit*100/nullif(ci.blocks_fetched,0) "C.Hit%", to_char(i.lastuse,'YYYY-MM-DD HH24:MI:SS') "Last Use"
  FROM pg_get_index i 
  JOIN pg_get_class ct on i.indrelid = ct.reloid and ct.relkind != 't'
  JOIN pg_get_class ci ON i.indexrelid = ci.reloid
  LEFT JOIN pg_get_ns n ON n.nsoid = ci.relnamespace
ORDER BY size DESC LIMIT 10000;

\pset tableattr 'id="params"'
WITH dset AS (
SELECT string_agg(setting,chr(10)) setting,a.name FROM
(SELECT btrim(CASE WHEN rolname IS NULL THEN '' ELSE 'User: '|| rolname ||' , ' END || CASE WHEN datname IS NULL THEN '' ELSE 'DB: '|| datname END ,' ,') || ' ==> ' ||setting AS setting
,split_part(setting,'=',1) AS name
FROM pg_get_db_role_confs drc
LEFT JOIN LATERAL unnest(config) AS setting ON TRUE
LEFT JOIN pg_get_db db ON drc.db = db.datid
LEFT JOIN pg_get_roles rol ON rol.oid = drc.setrole
ORDER BY 1,2 NULLS LAST
) AS a GROUP BY 2 ),
fset AS (SELECT coalesce(s.name,f.name) AS name
,s.setting,s.unit,s.source
,string_agg(f.sourcefile ||' - '|| f.setting || CASE WHEN f.applied = true THEN ' (applicable)' ELSE '' END ,chr(10)) FILTER (WHERE s.source != f.sourcefile OR s.source IS NULL ) AS loc
FROM pg_get_confs s FULL OUTER JOIN pg_get_file_confs f ON lower(s.name) = lower(f.name)
GROUP BY 1,2,3,4 ORDER BY 1)
SELECT fset.name "Name",fset.setting "Setting",fset.unit "Unit",fset.source "Current Source",
CASE WHEN dset.setting IS NULL THEN '' ELSE dset.setting ||chr(10) END || CASE WHEN fset.loc IS NULL THEN '' ELSE fset.loc END AS "Other Locations & Values"
FROM fset LEFT JOIN dset ON fset.name = dset.name;

\pset footer off
\pset tableattr 'id="tblextn"'
SELECT ext.oid,extname "Extension",rolname "Owner",nsname "Schema", extrelocatable "Relocatable?",extversion "Version" 
FROM pg_get_extension ext LEFT JOIN pg_get_roles ON extowner=pg_get_roles.oid
LEFT JOIN pg_get_ns ON extnamespace = nsoid;

\pset tableattr 'id="tblhba"'
WITH rules AS (SELECT * FROM pg_get_hba_rules WHERE mask IS NOT NULL AND addr NOT IN ('all','samehost','samenet')),
cidr AS (SELECT seq, COALESCE(sum((length(mask) - length(replace(mask, ip4mask.col1, ''))) / length(ip4mask.col1) * ip4mask.col2) ,
 sum((length(mask) - length(replace(mask, ip6mask.col1, ''))) / length(ip6mask.col1) * ip6mask.col2)) cidr_mask
FROM rules
LEFT JOIN (VALUES ('255',8),('254',7),('252',6),('248',5),('240',4),('224',3),('192',2),('128',1)) AS ip4mask (col1,col2)
  ON family(addr::inet) = 4
LEFT JOIN (VALUES ('8',1),('c',2),('e',3),('f',4)) AS ip6mask (col1,col2) ON family(addr::inet) = 6
GROUP BY 1),
rule_data AS (SELECT hba.seq ,typ ,db ,usr ,addr , cidr_mask , mask,
CASE WHEN addr IN ('all','samehost','samenet') OR ( mask IS NULL AND addr IS NOT NULL) THEN 'IPv4,IPv6'
 ELSE 'IPv'||family(addr::inet)
END  "IP" ,method , err, (addr||'/'||cidr_mask)::inet network_block
FROM  pg_get_hba_rules hba  LEFT JOIN cidr ON cidr.seq = hba.seq)
SELECT victim.seq "Line",victim.typ "Type",victim.db "Database",victim.usr "User",victim.addr "Address", victim.cidr_mask "CIDR Mask",victim.mask "DDN/Binary Mask" 
  ,victim."IP" "IP Ver.",victim.Method,victim.err,victim.network_block "Network Block", string_agg(shadower.seq::text,',') "In shadow of"
 FROM rule_data AS victim
LEFT JOIN rule_data AS shadower
ON  shadower.seq < victim.seq
    AND (
     (victim.typ = 'local' AND shadower.typ = 'local')
     OR (victim.typ = 'host' AND shadower.typ = 'host')
     OR (victim.typ = 'hostssl' AND shadower.typ IN ('host', 'hostssl'))
     OR (victim.typ = 'hostnossl' AND shadower.typ IN ('host', 'hostnossl'))
    )
    AND ( victim.typ = 'local'
     OR ( victim.network_block IS NOT NULL  AND shadower.network_block IS NOT NULL AND shadower.network_block >>= victim.network_block )
     OR shadower.addr = 'all'
    )
    AND (('replication' = ANY(victim.db) AND 'replication' = ANY(shadower.db) AND  victim.db <@ shadower.db)  OR
        (NOT ('replication' = ANY(victim.db)) AND ( shadower.db = '{all}'  OR victim.db <@ shadower.db ) ))
    AND (  shadower.usr = '{all}'  OR victim.usr <@ shadower.usr)
GROUP BY 1,2,3,4,5,6,7,8,9,10,11
ORDER BY 1;


\pset tableattr 'id="tblcs" class="lineblk thidden"'
WITH db_role AS (SELECT 
pg_get_activity.datid,rolname,count(*) FILTER (WHERE state='active') as active,
count(*) FILTER (WHERE state='idle in transaction') as idle_in_transaction,
count(*) FILTER (WHERE state='idle') as idle,
count(*) as totalcons,
count (*) FILTER (WHERE ssl = true) as sslcons,
count (*) FILTER (WHERE ssl = false) as nonsslcons
FROM pg_get_activity 
  LEFT JOIN pg_get_roles on usesysid=pg_get_roles.oid
  LEFT JOIN pg_get_db on pg_get_activity.datid = pg_get_db.datid
GROUP BY 1,2
ORDER BY 1,2),
db AS (SELECT datid,sum(active) "Active",sum(idle_in_transaction) "IdleInTrans",sum(idle) "Idle",sum(totalcons) "Total",sum(sslcons) "SSL",sum(nonsslcons) "NonSSL"
FROM db_role GROUP BY 1)
SELECT pg_get_db.datname "Database",
(SELECT json_agg(ROW(rolname,active,idle_in_transaction,idle,totalcons,sslcons,nonsslcons)) FROM db_role WHERE db_role.datid = pg_get_db.datid),
"Active","IdleInTrans","Idle","Total","SSL","NonSSL"
FROM pg_get_db LEFT JOIN db ON pg_get_db.datid = db.datid;

\pset tableattr 'id="tblusr" class="thidden"'
WITH rol_db AS (SELECT 
rolname,datname,count(*) FILTER (WHERE state='active') as active,
count(*) FILTER (WHERE state='idle in transaction') as idle_in_transaction,
count(*) FILTER (WHERE state='idle') as idle,
count(*) as totalcons,
count (*) FILTER (WHERE ssl = true) as sslcons,
count (*) FILTER (WHERE ssl = false) as nonsslcons
FROM pg_get_activity 
  join pg_get_roles on usesysid=pg_get_roles.oid
  join pg_get_db on pg_get_activity.datid = pg_get_db.datid
GROUP BY 1,2
ORDER BY 1,2),
rol AS (SELECT rolname,sum(active) "Active",sum(idle_in_transaction) "IdleInTrans",sum(idle) "Idle",sum(totalcons) "Total",sum(sslcons) "SSL",sum(nonsslcons) "NonSSL"
FROM rol_db GROUP BY 1)
SELECT pg_get_roles.rolname "User",
(SELECT json_agg(ROW(datname,active,idle_in_transaction,idle,totalcons,sslcons,nonsslcons)) FROM rol_db WHERE rol_db.rolname = pg_get_roles.rolname),
rolsuper "Super?",rolreplication "Repl?", CASE WHEN rolconnlimit > -1 THEN rolconnlimit ELSE NULL END  "Limit", 
CASE enc_method WHEN 'm' THEN 'MD5' WHEN 'S' THEN 'SCRAM' END "Enc",
"Active","IdleInTrans","Idle","Total","SSL","NonSSL"
FROM pg_get_roles LEFT JOIN rol ON pg_get_roles.rolname = rol.rolname;

\pset tableattr 'id="tableConten" name="waits" style="clear: left"'
\C 'WaitEvents'
SELECT COALESCE(wait_event,'CPU') "Event", count(*)::text "Event Count" FROM pg_pid_wait
WHERE wait_event IS NULL OR wait_event NOT IN ('ArchiverMain','AutoVacuumMain','BgWriterHibernate','BgWriterMain','CheckpointerMain','LogicalApplyMain','LogicalLauncherMain','RecoveryWalStream','SysLoggerMain','WalReceiverMain','WalSenderMain','WalWriterMain','CheckpointWriteDelay','PgSleep','VacuumDelay')
GROUP BY 1 ORDER BY count(*) DESC;

\pset tableattr 'id="tblsess" class="thidden"' 
\C 'Sessions'
SELECT * FROM (
    WITH w AS (SELECT pid, string_agg( wait_event ||': '|| cnt*100::float/2000 ||'%',', ') waits, sum(cnt) pidwcnt, max(max) itr_max, min(min) itr_min FROM
    (SELECT pid,COALESCE(wait_event,'CPU') wait_event,count(*) cnt, max(itr),min(itr) FROM pg_pid_wait GROUP BY 1,2 ORDER BY cnt DESC) pw GROUP BY 1),
  g AS (SELECT max(ts) ts,max(mx_xid) mx_xid FROM
  (SELECT MAX(state_change) as ts,MAX(GREATEST(backend_xid::text::bigint,backend_xmin::text::bigint)) mx_xid FROM pg_get_activity
    UNION
   SELECT NULL, pg_snapshot_xmax(snapshot)::xid::text::bigint mx_xid FROM pg_gather) a),
  wrk AS (select leader_pid, count(*) from pg_get_activity where leader_pid is not null group by 1),
  itr AS (SELECT max(itr_max) gitr_max FROM w)
  SELECT a.pid,to_jsonb(ROW(d.datname,application_name,client_hostname,sslversion,wrk.count)), a.state,r.rolname "User"
  , CASE WHEN a.leader_pid IS NULL THEN host(client_addr) ELSE 'Worker of ' || a.leader_pid END "client"
  , CASE query WHEN '' THEN '**'||backend_type||' process**' ELSE query END "Last statement"
  , g.ts - backend_start "Connection Since", g.ts - xact_start "Transaction Since", g.mx_xid - backend_xmin::text::bigint "xmin age",
   g.ts - query_start "Statement since",g.ts - state_change "State since", w.waits ||
   CASE WHEN (itr_max - itr_min)::float/itr.gitr_max*2000 - pidwcnt > 0 THEN
    ', Net/Delay*: ' || round(((itr_max - itr_min)::float/itr.gitr_max*2000 - pidwcnt)::numeric*100/2000,2) || '%'
   ELSE '' END waits
  FROM pg_get_activity a 
   LEFT JOIN w ON a.pid = w.pid
   LEFT JOIN itr ON true
   LEFT JOIN g ON true
   LEFT JOIN wrk ON wrk.leader_pid = a.pid
   LEFT JOIN pg_get_roles r ON a.usesysid = r.oid
   LEFT JOIN pg_get_db d on a.datid = d.datid
  ORDER BY "xmin age" DESC NULLS LAST) AS sess
WHERE waits IS NOT NULL OR state != 'idle';

\pset tableattr 'id="tblstmnt"'
\C 'Top Statements'
SELECT DENSE_RANK() OVER (ORDER BY ranksum) "Rank", "Statement",time_pct "DB.time%", calls "Execs",total_time::bigint/calls "Avg.ExecTime","Avg.Reads","C.Hit%" 
,"Avg.Dirty","Avg.Write","Avg.Temp(r)","Avg.Temp(w)" FROM 
(select query "Statement",total_time::bigint
, round((100*total_time/sum(total_time) OVER ())::numeric,2) AS time_pct, DENSE_RANK() OVER (ORDER BY total_time DESC) AS tottrank,calls
,total_time::bigint/calls, DENSE_RANK() OVER (ORDER BY total_time::bigint/calls DESC) as avgtrank
,DENSE_RANK() OVER (ORDER BY total_time DESC)+DENSE_RANK() OVER (ORDER BY total_time::bigint/calls DESC) ranksum
,shared_blks_read/calls "Avg.Reads",
shared_blks_dirtied/calls "Avg.Dirty",
shared_blks_written/calls "Avg.Write",
temp_blks_read/calls "Avg.Temp(r)",
temp_blks_written/calls "Avg.Temp(w)"
,100 * shared_blks_hit / nullif((shared_blks_read + shared_blks_hit),0) as "C.Hit%"
from pg_get_statements) AS stmnts
WHERE tottrank < 15 OR avgtrank < 15 ;

\pset tableattr 'id="tblreplstat"'
WITH M AS (SELECT GREATEST((SELECT(current_wal) FROM pg_gather),(SELECT MAX(sent_lsn) FROM pg_replication_stat))),
g AS (SELECT max(mx_xid) mx_xid FROM
(SELECT MAX(GREATEST(backend_xid::text::bigint,backend_xmin::text::bigint)) mx_xid FROM pg_get_activity
  UNION
 SELECT pg_snapshot_xmax(snapshot)::xid::text::bigint mx_xid FROM pg_gather) a)
SELECT usename AS "Replication User",client_addr AS "Replica Address",pid,state,
 pg_wal_lsn_diff(M.greatest, sent_lsn) "Transmission Lag (Bytes)",pg_wal_lsn_diff(sent_lsn,write_lsn) "Replica Write lag(Bytes)",
 pg_wal_lsn_diff(write_lsn,flush_lsn) "Replica Flush lag(Bytes)",pg_wal_lsn_diff(write_lsn,replay_lsn) "Replay at Replica lag(Bytes)",
 slot_name "Slot",plugin,slot_type "Type",datname "DB name",temporary,active,GREATEST(g.mx_xid-old_xmin::text::bigint,0) as "xmin age",
 GREATEST(g.mx_xid-catalog_xmin::text::bigint,0) as "catalog xmin age", GREATEST(pg_wal_lsn_diff(M.greatest,restart_lsn),0) as "Restart LSN lag(Bytes)",
 GREATEST(pg_wal_lsn_diff(M.greatest,confirmed_flush_lsn),0) as "Confirmed LSN lag(Bytes)"
FROM pg_replication_stat JOIN M ON TRUE
  FULL OUTER JOIN pg_get_slots s ON pid = active_pid
  LEFT JOIN g ON TRUE
  LEFT JOIN pg_get_db ON s.datoid = datid;

\pset tableattr 'id="tblchkpnt"'
SELECT round(checkpoints_req*100/tot_cp,1) "Forced Checkpoint %" ,
round(min_since_reset/tot_cp,2) "avg mins between CP",
round(checkpoint_write_time::numeric/(tot_cp*1000),4) "Avg CP write time (s)",
round(checkpoint_sync_time::numeric/(tot_cp*1000),4)  "Avg CP sync time (s)",
round(total_buffers::numeric*8192/(1024*1024),2) "Tot MB Written",
round((buffers_checkpoint::numeric/tot_cp)*8192/(1024*1024),4) "MB per CP",
round(buffers_checkpoint::numeric*8192/(min_since_reset*60*1024*1024),4) "Checkpoint MBps",
round(buffers_clean::numeric*8192/(min_since_reset*60*1024*1024),4) "Bgwriter MBps",
round(bg.buffers_backend::numeric*8192/(min_since_reset*60*1024*1024),4) "Backend MBps",
round(total_buffers::numeric*8192/(min_since_reset*60*1024*1024),4) "Total MBps",
round(buffers_alloc::numeric/total_buffers,3)  "New buffers ratio",
round(100.0*buffers_checkpoint/total_buffers,1)  "Clean by checkpoints (%)",
round(100.0*buffers_clean/total_buffers,1)   "Clean by bgwriter (%)",
round(100.0*bg.buffers_backend/total_buffers,1)  "Clean by backends (%)",
round(100.0*maxwritten_clean/(min_since_reset*60000 / delay.setting::numeric),2)   "Bgwriter halts (%) per runs",
coalesce(round(100.0*maxwritten_clean/(nullif(buffers_clean,0)/ lru.setting::numeric),2),0)  "Bgwriter halt (%) due to LRU hit",
round(min_since_reset/(60*24),1) "Reset days"
FROM pg_get_bgwriter
CROSS JOIN 
(WITH client AS (SELECT sum(evictions) buffers_backend FROM pg_get_io WHERE btype='c')  
SELECT 
    NULLIF(round(extract('epoch' from (select collect_ts from pg_gather) - stats_reset)/60)::numeric,0) min_since_reset,
    GREATEST(buffers_checkpoint + buffers_clean + COALESCE(client.buffers_backend,pg_get_bgwriter.buffers_backend),1) total_buffers,
    NULLIF(checkpoints_timed+checkpoints_req,0) tot_cp,
    COALESCE(client.buffers_backend,pg_get_bgwriter.buffers_backend) buffers_backend
FROM pg_get_bgwriter,client) AS bg
LEFT JOIN pg_get_confs delay ON delay.name = 'bgwriter_delay'
LEFT JOIN pg_get_confs lru ON lru.name = 'bgwriter_lru_maxpages';

\pset tableattr 'id="tbliostat"'
SELECT
CASE btype WHEN 'a' THEN 'Autovacuum' WHEN 'C' THEN 'Client Backend' WHEN 'G' THEN 'BG writer' WHEN 'b' THEN 'background worker' WHEN 'c' THEN 'Clients' 
  WHEN 'k' THEN 'Checkpointer' WHEN 'w' THEN 'WALSender' ELSE btype END As "Backend", 
sum(reads) "Reads",sum(writes) "Writes",sum(writebacks) "Writebacks", sum(extends) "Extends",sum(hits) "Hits",sum(evictions) "Evictions", sum(reuses) "Reuse", sum(fsyncs) "FSyncs"
FROM pg_get_io 
WHERE reads > 0 OR writes > 0  OR writebacks > 0 or extends > 0 OR hits > 0 OR evictions > 0 OR reuses > 0 OR fsyncs > 0
GROUP BY 1;
%>
<ol id="finditem" style="padding:2em;position:relative">
<h3 style="font: italic bold 2em Georgia, serif;text-decoration: underline; margin: 0 0 0.5em;">Findings:</h3>
</ol>
</div> <!--End of "sections"-->
<footer>End of <a href="https://github.com/jobinau/pg_gather">pgGather</a> Report</footer>
<script>
// Complete analysis data from pg_gather data as a JSON object "obj"
// A SQL query within <script> block might be confusing. But see the markers <% and %> for the pre-processing.
<% 
\pset format unaligned
\pset tuples_only on
SELECT 'obj='||to_jsonb(r)::text FROM
(SELECT 
  (select recovery from pg_gather) AS clsr,
  (SELECT to_jsonb(ROW(count(*),COUNT(*) FILTER (WHERE last_vac IS NULL), COUNT(*) FILTER (WHERE b.table_oid IS NULL AND r.n_live_tup != 0 ),COUNT(*) FILTER (WHERE last_anlyze IS NULL))) 
  FROM pg_get_rel r JOIN pg_get_class c ON r.relid = c.reloid AND c.relkind NOT IN ('t','p')
LEFT JOIN pg_tab_bloat b ON c.reloid = b.table_oid) AS tabs,
  (SELECT to_jsonb(ROW(COUNT(*),COUNT(*) FILTER (WHERE CONN < interval '15 minutes' ) )) FROM 
    (WITH g AS (SELECT MAX(state_change) as ts FROM pg_get_activity)
    SELECT pid,g.ts - backend_start CONN
    FROM pg_get_activity
    LEFT JOIN g ON true
    WHERE EXISTS (SELECT pid FROM pg_pid_wait WHERE pid=pg_get_activity.pid)
    AND backend_type='client backend') cn) AS cn,
  (SELECT to_jsonb(ROW(count(*) FILTER (WHERE relkind='p'), count(*) FILTER (WHERE relkind='r' AND relpersistence='u'), max(reloid))) from pg_get_class) as clas,
  (SELECT to_jsonb(ROW(count(*) FILTER (WHERE state='active' AND state IS NOT NULL), 
  count(*) FILTER (WHERE state='idle in transaction'), count(*) FILTER (WHERE state='idle'),
  count(*) FILTER (WHERE state IS NULL), count(*) FILTER (WHERE leader_pid IS NOT NULL) ,
  count(*),   count(distinct backend_type)))
  FROM pg_get_activity) as sess,
  (WITH curdb AS (SELECT 
  CASE WHEN (SELECT COUNT(*) FROM pg_srvr) > 0 
    THEN (SELECT trim(both '\"' from substring(connstr from '\"\w*\"')) "curdb" FROM pg_srvr WHERE connstr like '%to database%') ELSE (SELECT 'template1' "curdb")
  END),
  cts AS (SELECT COALESCE((SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) FROM pg_gather),current_timestamp) AS c_ts)
  SELECT to_jsonb(ROW(curdb,COALESCE(pg_get_db.stats_reset,:'reset_ts'),c_ts,days))
  FROM  curdb LEFT JOIN pg_get_db ON pg_get_db.datname=curdb.curdb
  LEFT JOIN LATERAL (SELECT GREATEST((EXTRACT(epoch FROM(c_ts- COALESCE(pg_get_db.stats_reset,:'reset_ts')))/86400)::bigint,1) as days FROM cts) AS lat1 ON TRUE
  LEFT JOIN cts ON true) as dbts,
  (WITH maxmxid AS (SELECT max(mxidage) FROM pg_get_db),
  topdbmx AS (SELECT array_agg(datname),maxmxid.max FROM pg_get_db JOIN maxmxid ON pg_get_db.mxidage=maxmxid.max AND pg_get_db.mxidage > 1000 GROUP BY 2)
  SELECT to_jsonb(ROW(array_agg,max)) FROM topdbmx) AS mxiddbs,
  (SELECT json_agg(pg_get_ns) FROM  pg_get_ns) AS ns,
  (SELECT json_agg(pg_get_tablespace) FROM pg_get_tablespace) AS tbsp,
  (SELECT to_jsonb((extract (EPOCH FROM (collect_ts - last_archived_time)), pg_wal_lsn_diff( current_wal,
  (coalesce(nullif(CASE WHEN length(last_archived_wal) < 24 THEN '' ELSE ltrim(substring(last_archived_wal, 9, 8), '0') END, ''), '0') || '/' || substring(last_archived_wal, 23, 2) || '000001'        ) :: pg_lsn )
  , last_archived_wal, last_archived_time::text || ' (' || CASE WHEN EXTRACT(EPOCH FROM(collect_ts - last_archived_time)) < 0 THEN 'Right Now'::text ELSE (collect_ts - last_archived_time)::text END  || ')'))
  FROM  pg_gather,  pg_archiver_stat) AS arcfail,
  (SELECT to_jsonb(ROW(max(setting) FILTER (WHERE name = 'archive_library'), max(setting) FILTER (WHERE name = 'cluster_name'),count(*) FILTER (WHERE source = 'command line'),any_value(setting) FILTER (WHERE name = 'block_size'),
  json_agg(row(name ,setting)) FILTER
   (WHERE name in ('block_size','max_identifier_length','max_function_args','max_index_keys','segment_size','wal_block_size') AND 
   (name,setting) NOT IN (('block_size','8192'),('max_identifier_length','63'),('max_function_args','100'),('max_index_keys','32'),('segment_size','131072'),('wal_block_size','8192'))
   OR (name = 'wal_segment_size' AND unit ='8kB' AND setting != '2048') OR (name = 'wal_segment_size' AND unit ='B' AND setting != '16777216')),
   count(*) FILTER (WHERE source IS NOT NULL)
  )) FROM pg_get_confs ) AS params,
  (SELECT json_agg(row(error,  name,  setting, sourcefile)) FROM pg_get_file_confs WHERE error IS NOT NULL) AS errparams,
  (WITH g AS (SELECT collect_ts,pg_start_ts,reload_ts,to_timestamp ( systemid >> 32 ) init_ts from pg_gather),
    r AS (SELECT LEAST(min(last_vac),min(last_anlyze)) known_ts FROM pg_get_rel)
  SELECT CASE WHEN (g.init_ts IS NULL OR g.reload_ts - g.init_ts > '80 minutes'::interval) AND ( r.known_ts > g.reload_ts OR r.known_ts IS NULL) AND g.collect_ts - g.reload_ts < '10 days'::interval 
  THEN g.reload_ts END crash_ts FROM g,r) crash,
  (WITH blockers AS (select array_agg(victim_pid) OVER () victim,blocking_pids blocker from pg_get_pidblock),
   ublokers as (SELECT unnest(blocker) AS blkr FROM blockers)
   SELECT json_agg(blkr) FROM ublokers
   WHERE NOT EXISTS (SELECT 1 FROM blockers WHERE ublokers.blkr = ANY(victim))) blkrs,
  (select json_agg((victim_pid,blocking_pids)) from pg_get_pidblock) victims,
  (SELECT  to_jsonb(( EXTRACT(epoch FROM (end_ts - collect_ts)),  pg_wal_lsn_diff(end_lsn, current_wal) * 60 * 60 / EXTRACT( epoch FROM (end_ts - collect_ts) ),
  wal_bytes/(extract (EPOCH FROM  (collect_ts - stats_reset))/3600)))
  FROM pg_gather JOIN pg_gather_end ON true
   LEFT JOIN pg_get_wal ON true) sumry,
  (SELECT json_agg((relname,maint_work_mem_gb)) FROM (SELECT relname,n_live_tup*0.2*6 maint_work_mem_gb 
   FROM pg_get_rel JOIN pg_get_class ON n_live_tup > 894784853 AND pg_get_rel.relid = pg_get_class.reloid 
   ORDER BY 2 DESC LIMIT 3) AS wmemuse) wmemuse,
   (WITH w AS (SELECT pid,count(*) cnt, max(itr) itr_max,min(itr) itr_min FROM pg_pid_wait group by 1),
   g AS (SELECT max(itr_max) gmax_itr FROM w)
  SELECT to_jsonb(ROW(SUM(((itr_max - itr_min)::float/gmax_itr)*2000 - cnt),max(gmax_itr),count(pid))) FROM w,g
   WHERE ((itr_max - itr_min)::float/gmax_itr)*2000 - cnt > 0) netdlay,
   (SELECT to_jsonb(ROW(count(*) FILTER (WHERE indisvalid=false)
   ,count(*) FILTER (WHERE numscans=0 AND tst.toastid IS NULL) --Unused Indexes of user tables
   ,count(*) FILTER (WHERE numscans=0 AND tst.toastid > 16384) --Unused TOAST index of user tables
   ,count(*) FILTER (WHERE tst.toastid IS NULL) --TOTAL User/Regular indexes
   ,count(*) FILTER (WHERE tst.toastid > 16384) --TOTAL Toast Indexes
   ,sum(size) FILTER (WHERE numscans=0)))
    FROM pg_get_index i
    JOIN pg_get_class ct ON i.indrelid = ct.reloid
    LEFT JOIN pg_get_toast tst ON ct.reloid = tst.toastid) induse,
    (WITH pkuk AS (SELECT indrelid,bool_or(indisprimary) pk,bool_or(indisunique) uk FROM pg_get_index GROUP BY indrelid)
    SELECT to_jsonb(ROW(COUNT(*) FILTER (WHERE pkuk.pk IS NULL OR NOT pkuk.pk), COUNT(*) FILTER (WHERE pkuk.uk IS NULL OR NOT pkuk.uk)))
    FROM pg_get_class c LEFT JOIN pkuk ON pkuk.indrelid = c.reloid WHERE c.relkind IN ('r')) nokey,
   (SELECT to_jsonb(ROW(sum(tab_ind_size) FILTER (WHERE relid < 16384),count(*))) FROM pg_get_rel) meta
) r;
%>

//pg_gather version
ver="31";
//Global object to hold json values passed from the SQL analysis
//obj={};
docurl="https://jobinau.github.io/pg_gather/";
//Currently supported PostgreSQL versions, Extensions
meta={"pgvers":["13.22","14.19","15.14","16.10","17.6"],"commonExtn":["plpgsql","pg_stat_statements","pg_repack"],"riskyExtn":["citus","tds_fdw","pglogical"]};

async function fetchJsonWithTimeout(url, timeout) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    try {
        const response = await fetch(url + "?_=" + new Date().getDate(), { signal: controller.signal });
        clearTimeout(timeoutId);
        if (!response.ok)  throw new Error("HTTP error! status:" + response.status );
        else return await response.json();
    } catch (error) {
        clearTimeout(timeoutId);
        if (error.name === "AbortError")  throw new Error("Request timed out");
        else throw error;
    }
}

mgrver="";
//walcomprz="";
datadir=""; //data directory is needed for understanding the tablespaces.
//Global variable to hold autovacuum_freeze_max_age, so that each table can be compared
autovacuum_freeze_max_age = 0;
//Global varaible to hold all emitted findings from different sections, which will finally presented in Findings section
let strfind = "";

//total DB size
totdb=0;
//Number of CPUs and Memory. Since many parameter are based on CPU and memory better to hold as a global variable.
totCPU=4;  //total number of CPUs, Minimum 4 is assumed, unless modified by the user
totMem=8;  //total memory in GB, Minimum 8GB is assumed, unless modified by the user
wrkld=""; //workload type (OLTP, OLAP etc.)
flsys= ""; //filesystem type (rglr vs cow)
//Prepare the list of blockers and Victims
let blokers = []
let blkvictims = []
//Parameter array with each parameter ("param") current value ("val"), recomendations.
let params = []

const canvas=document.createElement("canvas"); //canvas for getting the width of text
const canvascontext=canvas.getContext("2d"); //canvas context for getting the width of text
//another function passed into this functio will be called after the rendering is complete
function afterRenderingComplete(callback) { requestAnimationFrame(() => {  requestAnimationFrame(callback);  }); }

//function to check the parameters and display the findings, called from DOMContentLoaded event listner below.
async function doAllChecks(){
  const result = await fetchJsonWithTimeout("https://jobinau.github.io/pg_gather/meta.json",500).then(data => {
    meta = data;
    console.log("Data received:", data);})
    .catch(error => { console.error("Error fetching JSON:", error); });

  console.log("Starting all checks");
  afterRenderingComplete(() => {  console.log("This runs after the current rendering is complete."); 
  document.getElementById("sections").style="display:table";
  document.getElementById("busy").style="display:none";

  });
  checkgather();
  checkpars();
  checkdbs();
  checkconns();
  checkusers();
  checkdbtime();
  checksess();
  checkiostat();
  checkreplstat();
  //if (checkpars() == 1) { document.getElementById("finditem").innerHTML += strfind; return};  //Exit if there is any error in parameter collection
  checktabs();
  checktabPart();
  checkindex();
  checkextn();
  checkhba();
  checkstmnts();
  checkchkpntbgwrtr();
  checkfindings();
  console.log("All checks completed");
}

//When the DOM is ready
document.addEventListener("DOMContentLoaded", () => {
//obj=JSON.parse( document.getElementById("analdata").innerText);
// New code for preparting victims and blockers
if (obj.victims !== null){
//each victim will have associated blockers like : victim1 : blocker1, blocker2 
//prepare the list of victims
obj.victims.forEach(function(victim){
  blkvictims.push(victim.f1);
});
//prepare the list of blockers
obj.victims.forEach(function(victim){
  //for each victim there can be multiple blockers
  victim.f2.forEach(function(blker){
    //if the blocker is not appearing in victim's list and blocker is not allready added to blockers list, add 
    if (blkvictims.indexOf(blker) == -1 && blokers.indexOf(blker) == -1) blokers.push(blker);
  });
});
}
doAllChecks();
});

//window.onload = function() { };

//common function to set the titles for the table on mouseover. This will be called from each section
function setTitles(tr,tiltes){
  for(i=0;i<tiltes.length;i++) tr.cells[i].title=tiltes[i];
}


//Check the data collection of pg_gather
function checkgather(){
  const trs=document.getElementById("tblgather").rows
  let days,xmax=0;
  for (let i = 0; i < trs.length; i++) {
    val = trs[i].cells[1];
    switch(trs[i].cells[0].innerText){
      case "pg_gather" :
        val.innerText = val.innerText + "-v" + ver;
        break;
      case "Collected By" :
        if (val.innerText.slice(-2) < ver ) { val.classList.add("warn"); val.title = "Data is collected using old/obsolete version of gather.sql file. Please use v" + ver; 
        strfind += "<li><b>Old/obsolete version (v"+ val.innerText.slice(-2) + ") of pg_gather script (gather.sql) is used for data collection</b>. Please use v" + ver + " <a href='"+ docurl +"versionpolicy.html'>Details</a></li>";
        }
        break;
      case "In recovery?" :
        if(val.innerText == "true") {val.classList.add("lime"); val.title="Data collected at standby"; obj.primary = false;}
        else obj.primary = true;  //store that the instance is primary into obj
        break;
      case "System" :   //under assumption that columns will be sorted alphabetically. So this comes before "Time line"
        let startIndex = val.innerText.indexOf("(") + 1;
        days = parseInt(val.innerText.substring(startIndex,val.innerText.indexOf(" days", startIndex)));
        break;
      case "Latest xid" :
        xmax = parseInt(val.innerText);
        break;
      case "Oldest xid ref" :
        let diff=xmax - parseInt(val.innerText);
        val.innerText += " (" + (diff).toString() + " xids old)";
        if (diff > 10000) {val.classList.add("warn"); val.title = "The oldest transaction is " + diff + " xids old, as per xid horizon"; 
          strfind += "<li>The oldest transaction is <b>" + diff + " xids old</b>. This can have serious concequnces. Refer <a href='"+ docurl +"xidhorizon.html'>Details</a></li>";
        }
        break;
      case "Time Line" :
        let Failover = parseInt(val.innerText.substring(0,val.innerText.indexOf(" (")))-1;
        if (days > 30 && Failover > 5){
          let MTBF = days/Failover;
          if (MTBF < 180){
            val.classList.add("warn"); val.title = "Poor MTBF / Availability number. There were " + Failover + " failovers in " + days + " days." ;
            strfind += "<li><b>Poor MTBF / Availability number: "+ Math.round(MTBF) +" days!</b>. There were " + Failover + " failovers in " + days + " days</li>";
          }
        }
    }
  }
}

//check the obj content and display findings messages accordingly
function checkfindings(){
 //if the number of background processes from pg_stat_activity is less than 4, then it indicates the user don't have access to pg_stat* views properly
 let tmpstr = ""; //temporary string for hoding info during the string formatting
 if (obj.sess.f7 < 4){ 
  strfind += "<li><b>The pg_gather data is collected by a user who don't have necessary privilege OR Content of the output file (out.txt) is copy-pasted destroying the TSV format</b><br/><b>1.</b>Please run the gather.sql as a privileged user (superuser, rds_superuser etc.) or some account with pg_monitor privilege and <b>2.</b> Please provide the output file as it is without copy-pasting</li>"
  document.getElementById("tableConten").title="Waitevents data will be growsly incorrect because the pg_gather data is collected by a user who don't have proper privilege OR content of output file is copy-pasted. Please refer the Findings section";
  document.getElementById("tableConten").caption.innerHTML += "<br/>" + document.getElementById("tableConten").title
  document.getElementById("tableConten").classList.add("high");
 }
 if (obj.sess.f2 > 0) strfind += "<li><b>Found " + obj.sess.f2 + " session(s) in idle-in-transaction state</b>. This can cause poor concurrency. Details in <a href=#tblsess>Sessions</a> section. Consider improving the application code and design</li>";
 if (obj.cn.f1 > 0){
    strfind +="<li><b>" + obj.cn.f2 + " / " + obj.cn.f1 + " connections </b> in use are new. "
    if (obj.cn.f2 > 9 || obj.cn.f2/obj.cn.f1 > 0.7 ){
      strfind+="Please consider this for improving connection pooling"
    } 
    strfind += "</li>";
 }
 if (obj.induse.f1 > 0 ) strfind += "<li><b>"+ obj.induse.f1 +" Invalid Index(es)</b> found. Recreate or drop them. Refer <a href='"+ docurl +"InvalidIndexes.html'>Details</a></li>";
 if (obj.induse.f2 > 0 ) strfind += "<li><b>"+ obj.induse.f2 +" regular user indexes and " + obj.induse.f3 + " Toast Indexes are unused,</b> out of " + obj.induse.f4 + " user indexes and " + obj.induse.f5 + " Toast Indexes . Currently the unused indexes needs <b>additional "+ bytesToSize(obj.induse.f6) +" to cache</b>. <a href='"+ docurl +"unusedIndexes.html'>Details</a></li>";
 if (obj.mxiddbs !== null) strfind += "<li> Multi Transaction ID age : <b>" + obj.mxiddbs.f2 + "</b> for databases  <b>" + obj.mxiddbs.f1 + "</b> <a href='"+ docurl +"mxid.html'>Details</a></li>"
 if (obj.clas.f1 > 0) strfind += "<li><b>"+ obj.clas.f1 +" Natively partitioned tables</b> found. Tables section could contain partitions</li>";
 if (obj.clas.f2 > 0) strfind += "<li><b>"+ obj.clas.f2 +" Unlogged tables found.</b> These tables and associated indexes are ephemeral. <a href='"+ docurl +"unloggedtables.html'>Details</a></li>";
 if (obj.params.f3 > 10) strfind += "<li> Patroni/HA PG cluster :<b>" + obj.params.f2 + "</b></li>"
 if (obj.params.f5 != null && obj.params.f5.length > 0) strfind += "<li><b>Non-standard compile/Initialization time parameters detected : " + obj.params.f5.map(function(item) { return item.f1 + ": " + item.f2;}).join(", ") + "</b>. Custom Compilation is prone to bugs, and problems which are difficult to find</li>";
 if (obj.params.f6 == null || obj.params.f6 ==0 ) strfind += "<li><b>No Parameter values found. The data collection could be partial or corrupt Parameter file(s).</b></li>";
 if (obj.errparams !== null && obj.errparams.length > 0) {
   strfind += "<li> <b>Parameter file errors detected :<ul>";
   obj.errparams.forEach(function(t,idx){ strfind += "<li>" + t.f1 + " : " + t.f2 + " = "+ t.f3 +" in file " + t.f4 +"</li>" });
   strfind += "</ul></b></li>";
 }
 if (obj.crash !== null) strfind += "<li>Detected a <b>suspected crash / unclean shutdown around : " + obj.crash + ".</b> Please check the PostgreSQL logs</li>"
 if (obj.nokey.f1 > 0) strfind += "<li><b>"+ obj.nokey.f1 +" Tables without Primary Key</b> and <b>"+ obj.nokey.f2 +" Tables without niether Primary key nor Unique keys</b> found. Please refer <a href='"+ docurl +"pkuk.html'>Details</a></li>";
 if (obj.netdlay.f1 > 10) {
   if (obj.netdlay.f1 / obj.netdlay.f2 * 100 > 20 ){ strfind += "<li> There are <b>"+ obj.netdlay.f3 +" Sessions with considerable Net/Delays</b>"
   tmpstr = "Total <a href='"+ docurl +"NetDelay.html'>Net/Delay<a>"
   if (obj.netdlay.f1 / obj.netdlay.f2 > 1){
      tmpstr += " is <b>" + (obj.netdlay.f1 / obj.netdlay.f2).toFixed(1) + "Times ! </b> of overall server activity. which is huge"
   }else if(obj.netdlay.f1 / obj.netdlay.f2 > 0.1){
    tmpstr += " is equivalent to <b>" + (obj.netdlay.f1 * 100 / obj.netdlay.f2).toFixed(2) + "% </b> of server activity"
   }
   if (tmpstr.length > 100 ){
    strfind += "<li>" + tmpstr + "</li>"
    document.getElementById("tableConten").tFoot.children[0].children[0].innerHTML += tmpstr
   }
  }
 }
 for (let item of params) {  //Add all Parameter related warnigns.
    if (typeof item.warn != "undefined"){
     strfind += "<li>" + item.warn +"</li>";
    }
  }
 if(obj.clsr){
  strfind += "<li>PostgreSQL is in Standby mode or in Recovery</li>";
 }else{ // Primary server
   if ( obj.tabs.f2 > 0 ) strfind += "<li> <b>No vacuum info for " + obj.tabs.f2 + "</b> tables/objects </li>";
   if (obj.arcfail != null) { //entire information can go missing if no record comes to table : pg_gather, which could happen in aurora
   if (obj.arcfail.f1 == null) strfind += "<li>No working WAL archiving and backup detected. PITR may not be possible</li>";
   if (obj.arcfail.f1 > 300) strfind += "<li>No WAL archiving happened in last "+ Math.round(obj.arcfail.f1/60) +" minutes. <b>Archiving could be failing</b>; please check PG logs</li>";
   //Negative values for obj.arcfail.f2 should be expected because current LSN capture happens at the beginining
   if (obj.arcfail.f2 && obj.arcfail.f2 > 0) strfind += "<li>WAL archiving is <b>lagging by "+ bytesToSize(obj.arcfail.f2,1024)  +"</b>. Last archived WAL is : <b>"+ obj.arcfail.f3 +"</b> at "+ obj.arcfail.f4 +".<a href='"+ docurl +"walarchive.html'> Details<a></li>";
  }
  if (obj.wmemuse !== null && obj.wmemuse.length > 0){ strfind += "<li> Biggest <code>maintenance_work_mem</code> consumers are :<b>"; obj.wmemuse.forEach(function(t,idx){ strfind += (idx+1)+". "+t.f1 + " (" + bytesToSize(t.f2) + ")    " }); strfind += "</b></li>"; }
  if (obj.victims !== null && obj.victims.length > 0) strfind += "<li><b>" + obj.victims.length + " session(s) blocked.</b></li>"
  if (obj.sumry !== null){ strfind += "<li>Data collection took <b>" + obj.sumry.f1 + " seconds. </b>";
     if ( obj.sumry.f1 < 23 ) strfind += "System response is good</li>";
     else if ( obj.sumry.f1 < 28 ) strfind += "System response is below average</li>";
     else strfind += "System response appears to be poor</li>";
     strfind += "<li>Current WAL generation rate is <b>" + bytesToSize(obj.sumry.f2) + " / hour</b>"; 
     if (obj.sumry.f3 !== null ) strfind += ", Long term average WAL generation rate is <b>" + bytesToSize(obj.sumry.f3) + "/hour</b></li>"; 
     else strfind += "</li>" }
  //if ( mgrver.length > 0 &&  mgrver < Math.trunc(meta.pgvers[0])) strfind += "<li>PostgreSQL <b>Version : " + mgrver + " is outdated (EOL) and not supported</b>, Please upgrade urgently</li>";
  //if ( mgrver >= 15 && ( walcomprz == "off" || walcomprz == "on")) strfind += "<li>The <b>wal_compression is '" + walcomprz + "' on PG"+ mgrver +"</b>, consider a good compression method (lz4,zstd)</li>"
  if ( obj.clas.f3 > 50000 ) strfind += "<li>Currently <b>OID of pg_class stands at " + Number(obj.clas.f3).toLocaleString("en-US") + "</b>. indicating the usage of temporary tables / High DDL activity </li>";
  if (obj.meta.f1 > 15728640){ //metadata more than 15MB
    strfind += "<li>" + "The catalog metadata is :<b>" + bytesToSize(obj.meta.f1) + " For " + obj.meta.f2 + " objects. </b><a href='"+ docurl +"catalogbloat.html'> Details<a></li>"
  }
  if (obj.tbsp !== null && obj.tbsp.length > 0){
    const result=obj.tbsp.map(function(item) { return item.tsname + ": " + item.location;}).join(", ");
    strfind += "<li>Found additional <b>" + obj.tbsp.length + " tablespaces ("+ result +")</b> . <a href='"+ docurl +"tablespace.html'> Details<a></li>"
  }
 }  //END of Primary server
 if ( obj.tabs.f3 > 0 ) strfind += "<li> <b>No statistics available for " + obj.tabs.f3 + " tables/objects</b>, query planning can go wrong. <a href='"+ docurl +"missingstats.html'>Learn Details</a></li>";
 if ( obj.tabs.f1 > 10000) strfind += "<li> There are <b>" + obj.tabs.f1 + " tables/objects</b> in the database. Only the biggest 10000 will be displayed in the <a href=#tabInfo >Tables</a> section. Avoid too many tables/objects in single database. <a href='"+ docurl +"table_object.html'>Learn Details</a></li>";
 if (obj.ns !== null){
   let tempNScnt = obj.ns.filter(n => n.nsname.indexOf("pg_temp") > -1).length + obj.ns.filter(n => n.nsname.indexOf("pg_toast_temp") > -1).length ;
   strfind += "<li><b>" + (obj.ns.length - tempNScnt).toString()  + " Regular schema(s) and " + tempNScnt + " temporary schema(s)</b> in this database. <a href='"+ docurl +"schema.html'> Details<a></li>";
  }
 const sharedBuffers = params.find(p => p.param === "shared_buffers"); 
 const hugePages = params.find(p => p.param === "huge_pages");
 if ( sharedBuffers?.val > 2097152 && hugePages?.val !=  "on" ){
    strfind += "<li><b>IMPORTANT : Enabling and enforcing huge_pages is essential for stability and reliability</b>. Especially when the system has shared_buffers of <b>"+ bytesToSize(sharedBuffers.val*8192) +"</b>.</b><a href='"+ docurl +"params/huge_pages.html'>Details<a></li>"
 }
 if (obj.tabs.bloatTabNum > 0) strfind += "<li>Found <b>"+ obj.tabs.bloatTabNum +" bloated tables</b> in this database. This could affect performance. <a href='"+ docurl +"bloat.html'>Details</a></li>";
  //update the findings section
  document.getElementById("finditem").innerHTML += strfind;

}

function checkconns(){
  tab=document.getElementById("tblcs");
  tab.caption.innerHTML="<span>DB Connections</span>";
  const trs=tab.rows
  let nonssl=0;
  for (var i=1;i<trs.length;i++){
    tr=trs[i];
    if (tr.cells[7].innerText > 0) nonssl += parseInt(tr.cells[7].innerText);
    if (tr.cells[5].innerText > 20 && tr.cells[7].innerText/tr.cells[5].innerText > 0.5 ){
      tr.cells[7].classList.add("warn");
      tr.cells[7].title="Large precentage of unencrypted connections"
    }
  }
  if (nonssl > 10) strfind += "<li>Number of unencrypted connections : <b>"+ nonssl +"</b></li>"
  el=document.createElement("tfoot");  //footer element to connection details
  el.innerHTML = "<th colspan='7'>Active: "+ obj.sess.f1 +", Idle-in-transaction: " + obj.sess.f2 + ", Idle: " + obj.sess.f3 + ", Background: " + obj.sess.f4 + ", Workers: " + obj.sess.f5 + ", Total: " + obj.sess.f6 + "</th>";
  tab.appendChild(el);
}

//Event listeners for changing the CPU, Memory, Storage, Workload and Filesystem. Get the new recommendation
["cpus","mem","strg","wrkld","flsys"].forEach(function(t) {document.getElementById(t).addEventListener("change", (event) => { getreccomendation(); })});

function getreccomendation(){
  totMem = document.getElementById("mem").value;
  totCPU = document.getElementById("cpus").value;
  wrkld = document.getElementById("wrkld").value;
  flsys = document.getElementById("flsys").value;
  checkpars();
  let reccomandations = document.getElementById("paramtune").children[1];
  let reccos = "";
  for (let item of params) {
    if (typeof item.suggest != "undefined"){
     reccos += "<li>" + item.param + " = " + item.suggest + "&emsp;<a href='"+ docurl +"params/" + item.param +".html'>#Explanation</a></li>"
    }
  }
  reccomandations.innerHTML = reccos;
}

function flash(msg){
  var el=document.createElement("div");
  el.setAttribute("id", "cur");
  el.setAttribute("style", "position: fixed;top: 50%;left: 50%;transform: translate(-50%, -50%);");
  el.textContent = msg;
  document.body.appendChild(el);
  setTimeout(() => { el.remove();},2000);
}

//Copy the parameter recommendations as HTML
function copyashtml(){
  let elem = document.getElementById("paramtune");
  let paramtune = elem.cloneNode(true); //Deep clone and set style for the clone.
  paramtune.style="font-weight:initial;line-height:1.5em;background-color:#FAFFEA;border: 2px solid blue; border-radius: 5px; padding: 1em;box-shadow: 0px 20px 30px -10px grey";
  navigator.clipboard.writeText(paramtune.outerHTML);
  flash("Parameter recommendations are copied to clipboard as HTML code");
}

function copyrichhtml(){
  let elem = document.getElementById("paramtune")
  let paramtune = elem.cloneNode(true); //Deep clone and set style for the clone.
  paramtune.style="font-weight:initial;line-height:1.5em;background-color:#FAFFEA;border: 2px solid blue; border-radius: 5px; padding: 1em;box-shadow: 0px 20px 30px -10px grey";
  const clipboardItem = new ClipboardItem({	"text/plain": new Blob([paramtune.innerText],	{ type: "text/plain" }),
              "text/html": new Blob([paramtune.outerHTML],{ type: "text/html" })});
  navigator.clipboard.write([clipboardItem]);
  flash("Parameter recommendations are copied to clipboard as HTML Rich object");
}

//Convert bytes into human readable formats
function bytesToSize(bytes,divisor = 1000) {
  const sizes = ["B","KB","MB","GB","TB"];
  if (bytes == 0) return "0B";
  const i = parseInt(Math.floor(Math.log(bytes) / Math.log(divisor)), 10);
  if (i === 0) return bytes + sizes[i];
  return (bytes / (divisor ** i)).toFixed(1) + sizes[i]; 
}

function formatNumber(n) {
  const ranges = [ {divisor: 1e9, suffix: " Billion"}, {divisor: 1e6, suffix: " Million"}, {divisor: 1e3, suffix: " K"}];
  const range = ranges.find(r => n >= r.divisor);
  return range ? (n/range.divisor).toFixed(1) + range.suffix : n.toString();
};

//Set the tooltips for the Table head row.
function setheadtip(th,tips){
  for (i in tips) th.cells[i].title = tips[i];
}

//add key and value to json string
function updateJson(jsonString, key, value) {
  const jsonObject = JSON.parse(jsonString); // Parse the JSON string into a JavaScript object
  jsonObject[key] = value; // Add the new key-value pair
  return JSON.stringify(jsonObject); // Convert the updated object back to a JSON string
}


//Convert time format seperated by colon (:) to seconds for comparision
function DurationtoSeconds(duration){
    let days=0,dayIdx
    dayIdx=duration.indexOf("day")
    if(dayIdx>0){
      days=parseInt(duration.substring(0,dayIdx))
      if(duration[dayIdx+4] == "s") dayIdx=dayIdx+5
      else dayIdx=dayIdx+4
      duration=duration.substring(dayIdx)
    }
    const [hours, minutes, seconds] = duration.split(":");
    return days * 24 * 60 * 60 +(hours) * 60 * 60 + Number(minutes) * 60 + Number(seconds);
};

//******************* Parameter Despatch table implimentation v22 *******************/
var paramDespatch = {
  archive_mode : function(rowref){
    val=rowref.cells[1];
    if(obj.primary  == true && val.innerHTML == "off"){ val.classList.add("warn"); val.title="Primary server without WAL archiving configured. No PITR possible"}
  },
  archive_command : function(rowref) {
    val=rowref.cells[1];
    if (obj.params !== null && obj.params.f1 !== null && obj.params.f1.length > 0) { val.classList.add("warn"); val.title="archive_command won't be in-effect, because archive_library : " + obj.arclib + " is specified"  }
    else if (val.innerText.includes("barman")){ strfind += "<li><b>Use of Barman is detected</b>. Please be aware of the possible risks, if <code>rsync</code> is used as backup_method. <a href='"+ docurl +"barman.html'> Details<a></li>"; }
    else if (val.innerText.includes("cp ") || val.innerText.includes("rsync ")) { val.classList.add("warn"); strfind +="<li><b>Use of 'cp'/'rsync' command is detected in archive_commnad</b>, which is highly discouraged. Please use reliable backup tools for WAL archiving.<a href='"+ docurl +"cp.html'> Details<a></li></li>" }
    else if (val.innerText.length < 5) {val.classList.add("warn"); val.title="A valid archive_command is expected for WAL archiving, unless archive library is used" ; }
  },
  autovacuum : function(rowref) {
    val=rowref.cells[1];
    if(val.innerText != "on") { 
      val.classList.add("warn"); val.title="Autovacuum must be on" ;
      let param = params.find(p => p.param === "autovacuum");
      param["warn"] = "<b>Autovacuum is disabled</b>. This prevents essential maintenance, and can cause bloat and performance issues. Please enable autovacuum. <a href='"+ docurl +"params/autovacuum.html'>Details</a>";
      param["suggest"] = "on";
    }
  },
  autovacuum_max_workers : function(rowref) {
    val=rowref.cells[1];
    if(val.innerText > 3) { val.classList.add("warn"); val.title="High number of workers causes each workers to run slower because of the cost limit" ;
      let param = params.find(p => p.param === "autovacuum_max_workers");
      param["suggest"] = "3";
    }
  },
  autovacuum_vacuum_cost_limit: function(rowref){
    val=rowref.cells[1];
    if(val.innerText > 800 || val.innerText == -1 ) { val.classList.add("warn"); val.title="Better to specify this with a value less than 800" }
  },
  autovacuum_freeze_max_age: function(rowref){
    val=rowref.cells[1];
    autovacuum_freeze_max_age = Number(val.innerText);  //Store the value to global variable
    if (autovacuum_freeze_max_age > 800000000) val.classList.add("warn");
  },
  bgwriter_lru_maxpages: function(rowref){
    let param = params.find(p => p.param === "bgwriter_lru_maxpages");
    if (typeof param["suggest"] != "undefined"){
      val = val=rowref.cells[1];
      val.classList.add("warn"); 
      val.title="bgwriter_lru_maxpages is too low. Increase this to :" + param["suggest"];
    }
  },
  checkpoint_timeout: function(rowref){
    val=rowref.cells[1];
    if(val.innerText < 1200) { val.classList.add("warn"); val.title="Too small gap between checkpoints"
      let param = params.find(p => p.param === "checkpoint_timeout");
      param["suggest"] = "1800";
    }
  },
  data_directory: function(rowref){
    datadir=val.innerText;
  },
  deadlock_timeout: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); }, //TODO: Warn if is more than 1 mintue
  default_toast_compression: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "default_toast_compression");
    if (val.innerText != "lz4") { val.classList.add("warn"); val.title="Better to use lz4 for TOAST compression";
      param["suggest"] = "lz4";
     }
  },
  effective_cache_size: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); val.title=bytesToSize(val.innerText*8192,1024); }, 
  huge_pages: function(rowref){ 
    val=rowref.cells[1]; 
    if (val.innerText != "on" ) {
      val.classList.add("warn");
      let param = params.find(p => p.param === "huge_pages");
      param["suggest"] = "on";
    } else val.classList.add("lime"); 
  },
  huge_page_size: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); },
  hot_standby_feedback: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); },
  idle_session_timeout:function(rowref){ 
    val=rowref.cells[1]; 
    if (val.innerText > 0) { val.classList.add("warn"); val.title="It is dangerous to use idle_session_timeout. Avoid using this" }
  },
  idle_in_transaction_session_timeout: function(rowref){ 
    val=rowref.cells[1]; 
    if (val.innerText == 0){ val.classList.add("warn"); val.title="Highly suggestable to use atleast 5min to prevent application misbehaviour" }
    let param = params.find(p => p.param === "idle_in_transaction_session_timeout");
    param["suggest"] = "'5min'";
  },
  jit: function(rowref){ val=rowref.cells[1]; if (val.innerText=="on") { 
    val.classList.add("warn");
    val.title="Avoid JIT globally (Disable), Use only at smaller scope" 
    let param = params.find(p => p.param === "jit");
    param["suggest"] = "off";
  }},
  log_temp_files: function(rowref){
    val = val=rowref.cells[1];
    let param = params.find(p => p.param === "log_temp_files");
    if (typeof param["suggest"] != "undefined"){
      val.classList.add("warn"); 
      val.title="Heavy temporary file generation is detected. Consider setting log_temp_files=" + param["suggest"] ;
    } else if ((param["val"] > -1)){
      val.classList.add("lime");
      val.title="log_temp_files is already set. Analyze PostgreSQL log for problematic SQLs. Adjust parameter value if required";
    }
  },
  log_truncate_on_rotation: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "log_truncate_on_rotation");
    if (val.innerText == "off")  param["suggest"] = "on";
  },
  log_lock_waits: function(rowref){
    val=rowref.cells[1]; let param = params.find(p => p.param === "log_lock_waits");
    if(val.innerText == "off") param["suggest"] = "on";
  },
  lock_timeout: function(rowref){
    val=rowref.cells[1]; let param = params.find(p => p.param === "lock_timeout");
    if(val.innerText == "0") param["suggest"] = "'1min'";
  },
  maintenance_work_mem: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); val.title=bytesToSize(val.innerText*1024,1024); },
  max_connections: function(rowref){
    val=rowref.cells[1];
    val.title="Avoid value exceeding 10x of the CPUs"
    let conns = params.find(p => p.param === "max_connections");
    if( totCPU > 0 ){
      if(val.innerText > 10 * totCPU) { 
        val.classList.add("warn"); val.title="If there is only " + totCPU + " CPUs, max_connections above " + 10*totCPU + " Is not recommendable for performance and stability";
        conns["suggest"] = 10 * totCPU;
      }else { val.classList.remove("warn"); val.classList.add("lime");
        conns["suggest"] = 10 * totCPU;
      }
    } else if (val.innerText > 500) val.classList.add("warn")
      else val.classList.add("lime")
  },
  max_standby_archive_delay: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "max_standby_archive_delay");
    if (val.innerText > 300000){  val.classList.add("lime"); param["suggest"] = "30000"; val.title="max_standby_archive_delay is too high. could result in replication deylay";}
    else if (val.innerText < 30000){ val.classList.add("warn"); param["suggest"] = "30000"; val.title="max_standby_archive_delay is low. could result in query cancellation";}
  },
  max_standby_streaming_delay: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "max_standby_streaming_delay");
    if (val.innerText > 300000){ param["suggest"] = "30000"; val.classList.add("lime"); val.title="max_standby_streaming_delay is too high. could result in replication deylay";}
    else if (val.innerText < 30000){ val.classList.add("warn"); param["suggest"] = "30000"; val.title="max_standby_streaming_delay is low. could result in query cancellation";}
  },
  max_wal_size: function(rowref){
    val=rowref.cells[1];
    val.title=bytesToSize(val.innerText*1024*1024,1024);
    let param = params.find(p => p.param === "max_wal_size");
    if ( obj.sumry != null){
    let maxwal = obj.sumry.f2  > obj.sumry.f3  ? obj.sumry.f2  : obj.sumry.f3;
    if(val.innerText < maxwal/1048576) { val.classList.add("warn"); val.title += ",Too low compared to WAL generation rate" 
      param["suggest"] = "'"+ Math.ceil( maxwal/ 1073741824  / 10) * 10 + "GB'" ;  //convert the value to GB and round to 10GB
    }
    }
    if(val.innerText < 8192) { val.classList.add("warn"); val.title += ",Too low for production use" 
      param["suggest"] = "8192";
    }
    else val.classList.add("lime");
  },
  min_wal_size: function(rowref){
    val=rowref.cells[1];
    val.title=bytesToSize(val.innerText*1024*1024,1024);
    let param = params.find(p => p.param === "min_wal_size");
    if ( obj.sumry != null){
    let maxwal = obj.sumry.f2  > obj.sumry.f3  ? obj.sumry.f2  : obj.sumry.f3;
    if(val.innerText < maxwal/1048576) { val.classList.add("warn"); val.title += ",Too low compared to WAL generation rate" 
      param["suggest"] = "'"+ Math.ceil( maxwal/ 1073741824  / 10) * 10 / 2 + "GB'" ;  //convert the value to GB and round to 10GB (half of max_wal_size)
    }
    }
    if(val.innerText < 2048) { val.classList.add("warn"); val.title += ",Too low for production use" 
      param["suggest"] = "'2GB'";
    }
    else val.classList.add("lime");
  },
  parallel_leader_participation: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "parallel_leader_participation");
    if (wrkld == "oltp" && val.innerText == "off") param["suggest"] = "on";
    else if (wrkld == "olap" && val.innerText == "on") param["suggest"] = "off" ;
    else delete param["suggest"];
  },
  random_page_cost: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "random_page_cost");
    let strg = document.getElementById("strg").value;
  if ( strg == "ssd" ){
    if (val.innerText > 1.2){param["suggest"] = "1.1";   val.classList.add("warn");}
    else val.classList.add("lime");
  } else if ( strg == "san" ){
    if (val.innerText > 1.5){ param["suggest"] = "1.5";   val.classList.add("warn");}
    else val.classList.add("lime");
  } else { param["suggest"] = "4"; val.classList.add("lime")}; 
  },
  wal_keep_size: function(rowref){
    val=rowref.cells[1];
    val.title=bytesToSize(val.innerText*1024*1024,1024);
    val.classList.add("lime");
  },
  seq_page_cost: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "seq_page_cost");
    if (val.innerText != 1){ 
      param["suggest"] = "1"; val.classList.add("warn"); val.title="Avoid changing seq_page_cost value to anything other than 1, unless there is an unavoidable reason"; 
      param["warn"] = "seq_page_cost is specified as <b>" + val.innerText + "</b>. " + val.title; 
    }
  },
  server_version: function(rowref){
    val=rowref.cells[1];
    let setval = val.innerText.split(" ")[0]; mgrver=setval.split(".")[0];
    let sver_ver = params.find(p => p.param === "server_version");
    if ( mgrver < Math.trunc(meta.pgvers[0])){
      val.classList.add("warn"); val.title="PostgreSQL Version is outdated (EOL) and not supported";
      sver_ver["warn"] = "<b>Obsolete (End-of-Life) and Unsupported Version: PostgreSQL " + setval + ". IMPORTANT: Security vulnerabilities and bugs in obsolete versions won't be fixed.</b> <a href=https://why-upgrade.depesz.com/show?from="+setval+"&to="+ meta.pgvers.pop() + ">Understand the risk</a> ";
    } else {
      meta.pgvers.forEach(function(t){
        if (Math.trunc(setval) == Math.trunc(t)){
          if (t.split(".")[1] - setval.split(".")[1] > 0 ) { val.classList.add("warn"); val.title = t.split(".")[1] - setval.split(".")[1] + " Pending minor version udpate(s)."; 
           sver_ver["warn"] = "PostgreSQL <b>Version"+ val.innerText +"." + "</b>";
           if (val.title.length > 0) sver_ver["warn"] += " <b>IMPORTANT: " + val.title + "</b> <a href=https://why-upgrade.depesz.com/show?from="+setval+"&to="+t+">Understand the risk</a>";
          }
        }
      })  
    }
    if(val.classList.length < 1) val.classList.add("lime");  //if no problems found, just highlight the data
  },
  shared_buffers: function(rowref){
    val=rowref.cells[1];
    val.classList.add("lime"); val.title=bytesToSize(val.innerText*8192,1024);
    let param = params.find(p => p.param === "shared_buffers");
    if (val.innerText > 16384 && totMem == 8 ) { //if shared_bffer is above 128MB. Total memory is 8GB (default)
      totMem = Math.ceil(val.innerText * 8 * 4 / 1048576);  //Calculate RAM in GB as shared_buffers *4  
    } else if (val.innerText == 16384){  //If shared_buffers is PostgreSQL's default value (128MB)
      param["suggest"] = "'"+ totMem*0.25 + "'"; //Suggest 25% of the available memory
    }
    if(parseFloat(document.getElementById("mem").value) != totMem ){ //If the memory is changed by the user or calculated Memory is different
      document.getElementById("mem").value = totMem; //Update the memory value in the form
      document.getElementById("cpus").value = Math.ceil(totMem/4); //Update the CPU value in the form
      console.log("Memory is updated to " + totMem + "GB and CPU to " + Math.ceil(totMem/4));
    }
    if( totMem > 0 && ( totMem < val.innerText*8*0.2/1048576 || totMem > val.innerText*8*0.3/1048576 ))
      { 
      val.classList.add("warn"); val.title="Approx. 25% of available memory is recommended, current value of " + bytesToSize(val.innerText*8192,1024) + " appears to be off"; 
      param["suggest"]= "'"+ totMem*0.25 + "GB'";
      }
  },
  shared_preload_libraries: function(rowref){
    val=rowref.cells[1];
    if (val.innerText.length > 0 ){
      const elements = val.innerText.split(",");
      if (elements.length > 2) { val.classList.add("warn"); val.title="Too many extension libraries loaded. It could affect the performance" }
      if (elements.includes("repmgr")) strfind += "<li><b>Use of repmgr is found.</b> Please consider a more reliable HA framework <a href='"+ docurl +"ha.html'>Details</a></li>" 
    }
  },
  statement_timeout : function(rowref){
    val=rowref.cells[1];
    if(rowref.cells[3].innerText == "session" && rowref.cells[4].innerText.indexOf("/") < 0 ){
      rowref.cells[3].innerText= "default"; val.innerText="0";
      val.classList.add("warn"); val.title="It is important to set a value globally to avoid long running sessions and associated problems"
      let tmout = params.find(p => p.param === "statement_timeout");
      tmout["suggest"] = "'4h'";
      //Actual value need to be considering OLTP/OLAP workload
    }
  },
  synchronous_standby_names: function(rowref){
    val=rowref.cells[1];
    if (val.innerText.trim().length > 0){ val.classList.add("warn"); val.title="Synchronous Standby can cause session hangs, and poor performance"; }
  },
  track_io_timing: function(rowref){
    val=rowref.cells[1];
    if (val.innerText == "off"){
      val.classList.add("warn"); val.title="There is no good reason for track_io_timing to be off on any modern hardware. It is recommended to be on";
      let param = params.find(p => p.param === "track_io_timing");
      param["suggest"] = "on";
    }
  },
  wal_compression: function(rowref){
    val=rowref.cells[1]; val.classList.add("lime"); //walcomprz = val.innerText; highlight and update the global variable
    if(totCPU > 3){
      if (val.innerText == "off") { val.classList.add("warn"); val.title="Consider enabling wal_compression for better performance" 
        let param = params.find(p => p.param === "wal_compression");
        param["suggest"] = "'on'";
        if (mgrver >= 15) {
          param["warn"] = "<b>wal_compression is '"+ val.innerText+"' on PostgreSQL "+ mgrver +".</b> 'lz4' or 'zstd' is recommended, if available. <a href='"+ docurl +"params/wal_compression.html'> Details<a>"
          param["suggest"] = "'lz4'";
        }
      }
    }
  },
  wal_init_zero: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "wal_init_zero");
    if (flsys == "cow" && val.innerText == "on") { 
      val.classList.add("warn"); val.title="wal_init_zero is not recommended for Copy-on-Write filesystems (like ZFS, BTRFS, etc).";
      param["suggest"] = "off";
    } else if (flsys == "rglr" && val.innerText == "off") { 
      val.classList.add("warn"); val.title="wal_init_zero is recommended for regular filesystems (like ext4, xfs, etc).";
      param["suggest"] = "on";
    } else {
      val.classList.remove("warn");
      delete param["suggest"]
    }
  },
  wal_recycle: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "wal_recycle");
    if (flsys == "cow" && val.innerText == "on") { 
      val.classList.add("warn"); val.title="wal_recycle is not recommended for Copy-on-Write filesystems (like ZFS, BTRFS, etc).";
      param["suggest"] = "off";
    } else if (flsys == "rglr" && val.innerText == "off") { 
      val.classList.add("warn"); val.title="wal_recycle is recommended for regular filesystems (like ext4, xfs, etc).";
      param["suggest"] = "on";
    } else {
      val.classList.remove("warn");
      delete param["suggest"]
    }
  },
  work_mem: function(rowref){
    val=rowref.cells[1];
    val.title=bytesToSize(val.innerText*1024,1024) ;
    if(val.innerText > 98304){ val.classList.add("warn"); val.title += ", Avoid global settings above 64MB to avoid memory related issues"  }
    else val.classList.add("lime");
    let conns = params.find(p => p.param === "max_connections");
    let wmem = params.find(p => p.param === "work_mem");
    // 1/5th of the RAM can be given for total work_mem. So 1/5th of RAM / max_connections
    if ( totMem > 0.2 && conns.val > 1){
      wmem["suggest"] = "'" + Math.min(parseInt(totMem*1024/(5*parseInt(conns.val)) + 4 ),64) + "MB'";
    }
  },
  default : function(rowref) {}  //NOT used. remove after Test of time
};

// Interface for parameter evaluation, Second paramter is optional and can be called like : evalParam("autovacuum_vacuum_cost_limit"); 
var evalParam = function(param,rowref = null) {
  if (rowref != null && rowref.id == "") rowref.id=param;   //Assign the tr element id as the parameter name, This happens in the first invocation.
  else rowref = document.getElementById(param);  //Subsequent calls to the function is not expecting rowref passed in, Get the tr element by id already assigned to the parameter name
  //if despatcher has the specific paramteter section (only few parameters have)
  if (rowref == null) return; //If the rowref is null, return without doing anything. This happens when the parameter is not found in the HTML table
  if (paramDespatch.hasOwnProperty(param)){ 
    let paramJson = {}; paramJson["param"] = param; paramJson["val"] = rowref.cells[1].innerText; //Create a json object with parameter and value
    params.push(paramJson);    //Push the json object o params array
    paramDespatch[param](rowref);   //Finally calle the dispatcher function for the specific parameter with rowref as parameter
   }
}
//************End of Parameter Despatch table ***********************

//Check paramter values going though each in the HTML table
function checkpars(){
  tab=document.getElementById("params")
  tab.caption.innerHTML="<span>Parameters</span>"
  trs=tab.rows
  if (document.getElementById("params").rows.length > 1)
    for(var i=1;i<trs.length;i++)  evalParam(trs[i].cells[0].innerText,trs[i]);  //Despatcher function takes name of parameter and row of HTML table as parameters
  else { strfind += "<li><b>PARTIAL DATA COLLECTION. MAKE SURE TO RUN gather.sql SCRIPT USING AN ACCOUNT WITH THE REQUIRED PERMISSIONS AND WAIT FOR COMPLETION</b></li>"; return 1; }
 }

//Cells with value greater than autovacuum_freeze_max_age
function aged(cell){
 if(cell.innerHTML > autovacuum_freeze_max_age && cell.innerHTML > 200000000 ){ cell.classList.add("warn"); cell.title =  Number(cell.innerText).toLocaleString("en-US"); }
}

//Check Table Level info
function checktabs(){
  const startTime =new Date().getTime();
  tab=document.getElementById("tabInfo")
  tab.caption.innerHTML="<span>Tables</span> in '" + obj.dbts.f1 + "' DB" 
  const trs=document.getElementById("tabInfo").rows
  const len=trs.length;
  let bloatTabTot = 0; //Total bloated tables with more than 20% bloat
  setheadtip(trs[0],["Table Name and its OID","","Namespace / Schema OID","Bloat in Percentage","No. Live Rows/Tuples","No. Dead Rows/Tuples","Dead/Live ratio","Table (main fork) size in bytes",
  "Total Table size (All forks + TOAST) in bytes","Total Table size + Associated Indexes size in bytes","Age of main relation","","","Number of Vacuums per day","","Size of TOAST and its index",
   "Age of TOAST","Age of Table & TOAST","Number of Blocks Read/Fetched","Cache hit while reading","Time of last usage"]);
  [10,16,17].forEach(function(num){trs[0].cells[num].title+=". (Age of unfrozen tuple. Indication of the need for VACUUM FREEZE). Current autovacuum_freeze_max_age=" + autovacuum_freeze_max_age.toLocaleString("en-US")})
  for(var i=1;i<len;i++){
  //TODO : trs.forEach (convert the for loop to forEach if possible)
    tr=trs[i]; let TotTab=tr.cells[8]; TotTabSize=Number(TotTab.innerHTML); TabInd=tr.cells[9]; TabIndSize=(TabInd.innerHTML);
    if(TotTabSize > 5000000000 ) { TotTab.classList.add("lime"); TotTab.title = bytesToSize(TotTabSize) + "\nBig Table, Consider Partitioning, Archive+Purge"; 
    } else TotTab.title=bytesToSize(TotTabSize);
    //Tab above 20MB and with Index bigger than Tab
    if( TabIndSize > 2*TotTabSize && TotTabSize > 2000000 ){ TabInd.classList.add("warn"); TabInd.title="Indexes of : " + bytesToSize(TabIndSize-TotTabSize) + " is " + ((TabIndSize-TotTabSize)/TotTabSize).toFixed(2) + "x of Table " + bytesToSize(TotTabSize) + "\n Total : " + bytesToSize(TabIndSize)
    } else TabInd.title=bytesToSize(TabIndSize); 
    //Tab+Ind > 10GB
    if (TabIndSize > 10000000000) TabInd.classList.add("lime");
    if (tr.cells[3].innerText > 20 && TabIndSize > 5242880) { tr.cells[3].classList.add("warn"); bloatTabTot++; }
    //Check vacuum frequncy
    if (tr.cells[13].innerText / obj.dbts.f4 > 12){ tr.cells[13].classList.add("warn");  tr.cells[13].title="Too frequent vacuum runs : " + Math.round(tr.cells[13].innerText / obj.dbts.f4) + "/day"; }
    //Check the TOAST size
    if (tr.cells[15].innerText > 10000) { 
      tr.cells[15].title=bytesToSize(Number(tr.cells[15].innerText)); 
      //if TOAST is more than 10GB
      if (tr.cells[15].innerText > 10737418240) tr.cells[15].classList.add("warn")
      else tr.cells[15].classList.add("lime")
    }
    aged(tr.cells[10]);
    aged(tr.cells[16]);
    aged(tr.cells[17]);
    //Check reads per day
    if (tr.cells[18].innerText / obj.dbts.f4 > 262144 ){  //More than 2GB fetches per day. Specified in terms of blocks of 8196 bytes
      tr.cells[18].classList.add("lime"); 
      tr.cells[18].title="High Utilization : " + bytesToSize(Math.round(tr.cells[18].innerText * 8192 / obj.dbts.f4)) + "/day"; 
      //Inspect the cache hit ratio also if utilization is high.
      if(tr.cells[19].innerText < 40 ){ tr.cells[19].classList.add("warn"); tr.cells[19].title="Poor cache hit ratio, Results in high DiskReads"; }
      else if (tr.cells[19].innerText < 70) tr.cells[19].classList.add("lime");
     }
  }
const endTime = new Date().getTime();
obj.tabs.bloatTabNum = bloatTabTot;
console.log("time taken for checktabs :" + (endTime - startTime));
}

function checktabPart(){ //check partitioned tables
  const tab=document.getElementById("tabPart");
  tab.caption.innerHTML="<span>Partitioned Tables</span> in '" + obj.dbts.f1 + "' DB";
  if (tab.rows.length < 2){ tab.tBodies[0].innerHTML="No Partitioned tables found."; return;}
  const trs=tab.rows
  setheadtip(trs[0],["Partitioned Table Name","","Type of Partitioning (Declerative vs Inheritance)","No. of Partitions","Total Table Size","Total Index Size","Precentate of fetches coming from a single partition (bigger the better)"]);
  const len=trs.length;
  if (len > 4) strfind += "<li><b>"+ (len-1).toString() +" Partitioned Tables found.</b> Please check the partitioning strategy and its effectiveness. <a href='"+ docurl +"partition.html'>Details</a></li>"
  for(var i=1;i<len;i++){
    tr=trs[i];
    if (tr.cells[3].innerText > 16 ) { tr.cells[3].classList.add("lime"); tr.cells[3].title = "Ensure proper partition pruning in SQL statements"; 
    } else if (tr.cells[3].innerText == 0 ) { tr.cells[3].classList.add("warn"); tr.cells[3].title = "No Partitions found"; }
    if (tr.cells[4].innerText/tr.cells[3].innerText > 5368709120) { tr.cells[4].classList.add("warn"); tr.cells[4].title = "Average per partition size is :" + bytesToSize(tr.cells[4].innerText/tr.cells[3].innerText) ; }
  }
}

//Inspect database level info
function checkdbs(){
  //second column in the table is hidden, be careful
  const trs=document.getElementById("dbs").rows
  const len=trs.length;
  let aborts=[];  //array of dbnames where high aborts are happening
  let strtmp="";  //string to hold temp file generation info.
  //trs[0].cells[6].title="Average Temp generation Per Day"; trs[0].cells[7].title="Average Temp generation Per Day"; trs[0].cells[9].title="autovacuum_freeze_max_age=" + autovacuum_freeze_max_age.toLocaleString("en-US");
  setTitles(trs[0],["Database Name","","Avg. No. of commits per day","Avg. No. of Aborts/Rollbacks per day","Avg. DML Operations per day","Cache Hit Ratio (%)","Avg. No. Temp files generated per day","Avg Temp File Size in bytes per day","Database size in bytes","Age of unfrozen tuples in database"]);
  for(var i=1;i<len;i++){
    tr=trs[i];
    if(obj.dbts !== null && tr.cells[0].innerHTML == obj.dbts.f1) tr.cells[0].classList.add("lime");
    //High number of transaction aborts/rollbacks
    if(tr.cells[3].innerHTML > 4000){ tr.cells[3].classList.add("warn"); tr.cells[3].title = "High number of transaction aborts/rollbacks. Please inspect PostgreSQL logs"; 
     aborts.push(tr.cells[0].innerHTML)
     }
    [7,8].forEach(function(num) {  if (tr.cells[num].innerText > 1048576) { if(tr.cells[num].classList.length < 1) tr.cells[num].classList.add("lime"); tr.cells[num].title=bytesToSize(tr.cells[num].innerText) } });
    //More than 50GB temp generation per day. removing class even if it is not there is not causing any error
    if(tr.cells[7].innerHTML > 50000000000) {  
      tr.cells[7].classList.remove("lime"); tr.cells[7].classList.add("warn"); 
      let str = " temp file generation per day!. It can cause I/O performance issues." 
      let param = params.find(p => p.param === "log_temp_files");
      if ( param && param["val"] == -1 ) { 
        param["suggest"] = "'100MB'"; 
        str += "Consider setting log_temp_files=" + param["suggest"] + " to collect the problematic SQL statements to PostgreSQL logs";
      }else{
        str += "log_temp_files is already enabled, Analyze the PostgreSQL logs to check the problematic SQL statements";
      }
      evalParam("log_temp_files");
      if (strtmp != "") strtmp+= ","
      strtmp +=  tr.cells[7].title +"/day on "+tr.cells[0].innerHTML; 
      tr.cells[7].title += str;
    }
    totdb=totdb+Number(tr.cells[8].innerText);
    aged(tr.cells[9]);
  }
  if (aborts.length >0)  //Mention the aborts in findings.  future append aborts array to json  : obj.aborts=aborts;
   strfind += "<li>High number of transaction aborts/rollbacks in databases : <b>" + aborts.toString() + "</b>, please inspect PostgreSQL logs for more details</li>" ; 
  if (strtmp != "") strfind += "<li>High temp file generation : <b>" + strtmp + "</b></li>"; 

  //Add footer to database details table at the top
  var el=document.createElement("tfoot");
  el.innerHTML = "<th colspan='9'>**Averages are Per Day. Total size of "+ (document.getElementById("dbs").tBodies[0].rows.length - 1) +" DBs : "+ bytesToSize(totdb) +"</th>";
  dbs=document.getElementById("dbs");
  dbs.appendChild(el);

}

function checkextn(){
  const tab=document.getElementById("tblextn");
  tab.caption.innerHTML="<span>Extensions</span> in '" + obj.dbts.f1 + "' DB" 
  const trs=tab.rows
  const len=trs.length;
  let riskyExtn=[];
  if (len > 4) strfind += "<li><b>"+ (len-1).toString() +" Additional Extensions found.</b> Extensions can cause considerable overhead and performance degradataion. <a href='"+ docurl +"extensions.html'>Details</a></li>"
  for(var i=1;i<len;i++){
    tr=trs[i];
    //if the extension name is found in riskyExtn list, warn
    if (meta.riskyExtn.includes(tr.cells[1].innerHTML)){ tr.cells[1].classList.add("warn"); tr.cells[1].title = "Risky to use in mission critical systems without support aggrement. Crashes are reported" ; }
    //else if the extension name is not found in meta.commonExtn, highlight it.
    else if (!meta.commonExtn.includes(tr.cells[1].innerHTML)) tr.cells[1].classList.add("lime");
  }
}

function checkusers(){
  tab=document.getElementById("tblusr");
  tab.caption.innerHTML="<span>Users/Roles</span>  and connections"
  const trs=tab.rows
  let supr=0;
  for (var i=1;i<trs.length;i++){
    tr=trs[i];
    if(tr.cells[2].innerText == "t"){
      tr.cells[2].classList.add("lime");
      tr.cells[2].title =  "Super User"
      supr++;
    }
    if(tr.cells[5].innerText == "MD5"){
      tr.cells[5].classList.add("warn");
      tr.cells[5].title="Consider switching to SCRAM for better security whever possible"
    }
  }
  if (supr > 2 ) strfind += "<li>There are <b>" + supr + " Super user accounts</b>, consider this from the security standpoint</li>"
}

function checkhba(){
  tab=document.getElementById("tblhba");
  tab.caption.innerHTML="<span>HBA rules</span> analysis for security"
  const trs=tab.rows
  let shadowed=0; //Count of shadowed rules
  for (var i=1;i<trs.length;i++){
    tr=trs[i];
    if (!["::1","127.0.0.1","","samehost"].includes(tr.cells[4].innerText.trim()) && tr.cells[8].innerText.trim() != "reject" ){
      if(tr.cells[7].innerText == "IPv4"){
        if(tr.cells[5].innerText < 24){ 
          tr.cells[5].classList.add("warn");
          tr.cells[5].title="Avoid keeping the subnet mask wide open"
        } else if(tr.cells[5].innerText < 32) tr.cells[5].classList.add("lime")

        if(tr.cells[8].innerText == "md5"){
          tr.cells[8].classList.add("warn");
          tr.cells[8].title="Consider switching to SCRAM (scram-sha-256) for better security whever possible"
        }else if(tr.cells[8].innerText == "trust"){
          tr.cells[8].classList.add("warn");
          tr.cells[8].title="Avoid blindly trusting connection from outside"
        }
      }
      if(tr.cells[4].innerText == "all"){
          tr.cells[4].classList.add("warn");
          tr.cells[4].title="Avoid allowing connetions from all addresses"
      } else tr.cells[4].classList.add("lime")
    }
    if(tr.cells[11].innerText.trim() != ""){
      tr.cells[11].classList.add("high","warn");
      tr.cells[0].classList.add("high");
      tr.title="This rule is in shadow of the previous rule(s) and will never be used"
      shadowed++;
    }
  }
  if (shadowed > 0) strfind += "<li><b>" + shadowed + " shadowed HBA rules detected</b>, which will never be used. Please review the rules carfully and remove the shadowed ones</li>";
}

//Sort logic
const getCellValue = (tr, idx) => tr.children[idx].innerText || tr.children[idx].textContent;
const comparer = (idx, asc) => (a, b) => ((v1, v2) =>   v1 !== "" && v2 !== "" && !isNaN(v1) && !isNaN(v2) ? v1 - v2 : v1.toString().localeCompare(v2))(getCellValue(asc ? a : b, idx), getCellValue(asc ? b : a, idx));
document.querySelectorAll("th").forEach(th => th.addEventListener("click", (() => {
  const table = th.closest("table");
  th.style.cursor = "progress";
  var el=document.createElement("div");
  el.setAttribute("id", "cur");
  if (this.asc) el.textContent = "⬆";
  else el.textContent = "⬇";
  th.appendChild(el);
  setTimeout(() => { el.remove();},1000);
  setTimeout(function (){
  Array.from(table.querySelectorAll("tr:nth-child(n+2)")).sort(comparer(Array.from(th.parentNode.children).indexOf(th), this.asc = !this.asc)).forEach(tr => table.appendChild(tr) );
  setTimeout(function(){th.style.cursor = "pointer";},10);
  },50);
})));

/////############## Pop-up details box######################
//Pop-up at DB info
function dbsdtls(e){
  if (e.target.matches("tr td:first-child")){
  th = e.target.parentNode;  
  let o=th.cells[1].innerText.split(",");
  let str= th.cells[0].classList.contains("lime")?" (pg_gather connected)<br/>":""  //ternary operator to check if the first cell has class "lime"
  return "<b>" + th.cells[0].innerText + "</b>" + str + 
   "<c> Inserts per day : " + o[0] + "</c><c>Updates per day : " + o[1] + "</c><c>Deletes per day : " 
   + o[2] + "</c><c>Stats Reset : " + o[3] + "</c><c>DB oid(dbid) :" + o[4] + "</c><c>Multi Txn Id Age :" + o[5] + "</c>" 
   + "<c>Encoding : " + o[6] + "</c><c>Collation : " + o[7] + "</c>";
  }
}

//Pop-up for Tables.
function tabInfodtls(e){
  //let o=JSON.parse(th.cells[1].innerText);
  let td = e.target;
  let tr = td.parentNode;
  if (e.target.matches("tr td:first-child")){
  let o=tr.cells[1].innerText.split(",");
  let vac=tr.cells[13].innerText; 
  let ns=obj.ns.find(el => el.nsoid === JSON.parse(tr.cells[2].innerText).toString()); //lookup cells[2] value, the oid of NS in the obj.ns json collection 
  let str=""
  //[0]=r.relid [1]=r.n_tup_ins [2]=r.n_tup_upd [3]=r.n_tup_del [4]=r.n_tup_hot_upd [5]=isum.totind [6]=isum.ind0scan [7]=isum.pk [8]=isum.uk
  //[9]=inhp.relname [10]=inhp.relkind [11]=c.relfilenode [12]=c.reltablespace, [13]=c.reloptions
  if (o[10] == "r") str += "<c>Inheritance Partition of : " + o[9] + "</c>";
  if (o[10] == "p") str += "<c>Native Partition of : " + o[9] + "</c>";
  if (o[5] !== null) str += "<c>Total Indexes: " + o[5] + "</c>";
  if (o[6] !== null) str += "<c>Unused Indexes: " + o[6] + "</c>";
  str += (o[7] > 0) ? "<c>Primary key: Exists</c>" : "<c>No Primary key</c>";  //ternary operator to check if primary key exists
  if (o[8]-o[7] > 0) str += "<c>Unique keys (than PK): " + (o[8]-o[7]) + "</c>";
  let days=(obj.dbts.f4 < 1) ? 1 : obj.dbts.f4; //if dbts.f4 is less than 1, set it to 1 to avoid division by zero 
  //if (obj.dbts.f4 < 1) obj.dbts.f4 = 1;
  if (vac > 0) str +="<c>Vacuums / day : " + Number(vac/days).toFixed(1) + "</c>";
  str += "<c>Inserts / day : " + Math.round(o[1]/days) + "</c>";
  str += "<c>Updates / day : " + Math.round(o[2]/days) + "</c>";
  str += "<c>Deletes / day : " + Math.round(o[3]/days) + "</c>";
  str += "<c>HOT.updates / day : " + Math.round(o[4]/days) + "</c>";
  str += "<c>Rel.filename : " + o[11] + "</c>";
  if (o[12] < 16384) str += "<c>Tablespace : pg_default </c>"; 
  else{
    let tbsp = obj.tbsp.find(el => el.tsoid === JSON.parse(o[12]).toString()); 
    str += "<c>Tablespace : " + o[12] + " (" + tbsp.tsname + " : " + tbsp.location + ")</c>"; 
  }
  if (o[13] !== null ) str += "<c>Current Settings : " + o[13] + "</c>";
  if(o[2] > 0 || vac/days > 50){
    str += "<br><b><u>RECOMMENDATIONS : </u></b>"
  if (o[2] > 0) str += "<c>FILLFACTOR :" + Math.round(100 - 20*o[2]/(o[2]+o[1])+ 20*o[2]*o[4]/((o[2]+o[1])*o[2])); + "</c>" //Refer FILLFACTOR in sqlstatement.md
  if (vac/days > 50) { 
    let threshold = Math.round((Math.round(o[2]/days) + Math.round(o[3]/days))/48);  //(UPDATEs per day + DELETEs per day) / 48
    if (threshold < 500) threshold = 500;
    str += "<c>AUTOVACUUM : autovacuum_vacuum_threshold = "+ threshold +", autovacuum_analyze_threshold = " + threshold + "</c>"
  }}
  return "<b>" + tr.cells[0].innerText + "</b><c>OID : " + o[0] + "</c><c>Schema : " + ns.nsname + "</c>" + str;
}else{ // other than first cell
 let tdSiblings = Array.from(tr.querySelectorAll("td"));
 let thIndex = tdSiblings.indexOf(td);
 //console.log("thIndex: " + thIndex);
 switch (thIndex) {
 case 7: //Rel size
 case 8: //Tot.Tab size
 case 9: //Tab+Ind size
 case 15: //Toast + Ind
   return bytesToSize(tr.cells[thIndex].innerText);
 case 10:
 case 16:
 case 17:
  return formatNumber(tr.cells[thIndex].innerText)
 default:
   return "";
 }
}
}

//Pop-up for Session details
function sessdtls(th){
  let o=JSON.parse(th.cells[1].innerText); let str="";
  if (o.f1 !== null) str += "Database :" + o.f1 + "<br/>";
  if (o.f2 !== null && o.f2.length > 1 ) str += "Application :" + o.f2 + "<br/>";
  if (o.f3 !== null) str += "Client Host :" + o.f3 + "<br/>";
  if (o.f4 != null) str += "Communication :" + o.f4 + "<br/>";
  if (o.f5 != null) str += "Workers :" + o.f5 + "<br/>";
  //o.f6 is injected from checksess() into JSON. "f6" is hard coded.
  if (typeof o.f6 != "undefined") str += "<div class=warn>" + o.f6 + "<div>";  //This may need to change to proper add element
  if (str.length < 1) str+="Independent/Background process";
  return str;
}

function userdtls(tr){
if(tr.cells[1].innerText.length > 2){
  let o=JSON.parse(tr.cells[1].innerText); let str="<b><u>Connections per DB by user '"+tr.cells[0].innerText+"'</u></b><br>";
  for(i=0;i<o.length;i++){
    str += (i+1).toString() + ". Database:" + o[i].f1 + " Active:" + o[i].f2 + ", IdleInTrans:" + o[i].f3  + ", Idle:" + o[i].f4 +  " <br>";
  }
  return str
} else return "No connections"
}

function dbcons(tr){
if(tr.cells[1].innerText.length > 2){
  let o=JSON.parse(tr.cells[1].innerText); let str="<b><u>User connections to DB \'"+ tr.cells[0].innerText +"'</u></b><br>";
  for(i=0;i<o.length;i++){
    str += (i+1).toString() + ". User:" + o[i].f1 + " Active:" + o[i].f2 + ", IdleInTrans:" + o[i].f3  + ", Idle:" + o[i].f4 +  " <br>";
  }
  return str
} else return "No connections"
}

//Insert popup div element to every HTML Table with hidden columns
// document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("mouseenter", (() => {
//   tr=td.parentNode;
//   tab=tr.closest("table");
//   var el=document.createElement("div");
//   el.setAttribute("id", "dtls");
//   el.setAttribute("align","left");
//  // el.addEventListener("mouseenter", () => {
//  //     console.log("Mouse ENTERED popup");
//  //   });
//   el.addEventListener("mouseleave", (event) => {
//       if (!td.contains(event.relatedTarget)) { // Check if the mouse is moving back to the parent
//         el.remove(); // Remove the child element when mouse leaves child, But not going back to parent
//       } //else { console.log("Mouse LEFT popup (going back to parent)"); }
//     });
//   if(tab.id=="dbs") el.innerHTML=dbsdtls(tr);
//   if(tab.id=="tabInfo") el.innerHTML=tabdtls(tr);
//   if(tab.id=="tblsess") el.innerHTML=sessdtls(tr);
//   if(tab.id=="tblusr") el.innerHTML=userdtls(tr);
//   if(tab.id=="tblcs") el.innerHTML=dbcons(tr);
//   td.appendChild(el);
// })));

function tabPartdtls(e){

  if (e.target.matches("tr td:first-child")){
  th = e.target.parentNode;
  //let str= th.cells[1].innerText;
  //str = str.replace('/(\\w+)/g', '''"$1"''');  //Results in js: str = str.replace(/(\w+)/g, '"$1"');
  let o=th.cells[1].innerText.split(",");
  let str = "";
  if (o[0]) str += "<c>Default Parittion :" + o[0] + "<c>";
  else if(th.cells[3].innerText > 0) str+="<c class=lime>No Default Partition Found<c>";
  if (o[1] && o[1]>1) str += "<c class=warn>"+ o[1] + "rows/tuples in the default partition<c>"
  return str;
  }
}


document.querySelectorAll(".thidden").forEach(table => {
  //Event listener for mouseenter
  table.addEventListener("mouseenter", (e) => {
    let str = ""
    const td = e.target;
    if (td.innerText.trim().length < 1 ) return; //if the td is empty, return without doing anything
    if (typeof window[e.currentTarget.id + "dtls"] === "function") { //if there is a function with the name of table id + dtls
     str = window[e.currentTarget.id + "dtls"](e);   //pass the event to the function and get the processed string
    } else if (e.target.matches("tr td:first-child")){    //TODO : Slowly move all the functions to the above if condition
      const tr = td.parentNode;
      const tab = tr.closest("table");
      str = tab.id === "tblsess" ? sessdtls(tr) :
                     tab.id === "tblusr" ? userdtls(tr) :
                     tab.id === "tblcs" ? dbcons(tr) : "";
    }  
    if ( str ) { //if the string is not empty, create a popup
      var el = document.createElement("div");
      el.setAttribute("id", "dtls");
      el.setAttribute("align", "left");
      if (td.align != "left") {
        el.style.cssText += "left: 100%; top: 80%";
      } else {
        computedStyle=window.getComputedStyle(td); //get the style of the current td element and copy it to canvas context for measuring text width
        canvascontext.font = computedStyle.fontStyle + " " + computedStyle.fontWeight + " " + computedStyle.fontSize + " " + computedStyle.fontFamily;
        el.style.left=canvascontext.measureText(td.textContent).width+8+"px";
      }
      el.addEventListener("mouseleave", (event) => {
      if (!td.contains(event.relatedTarget)) el.remove(); // Check if the mouse is moving back to the parent, Remove the child element if it is leaving, but not going back to parent
      })
      el.innerHTML= str;
      td.appendChild(el); 
    }
  }, true); // `true` for capture phase (better performance)

  //Event listener for double click to copy details
  table.addEventListener("dblclick", function(event) {
    if (event.target.matches("tr td:first-child")) {
      navigator.clipboard.writeText(event.target.children[0].innerText);
      flash("Details copied to clipboard");
    }
  });


  //Event listener for mouseleave to remove the popup on mouse leave
  table.addEventListener("mouseleave", (e) => {
        if (e.target.matches("tr td")) e.target.children[0]?.remove();
  }, true); // `true` for capture phase (better performance)

});

// document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("dblclick", (() => {
//   navigator.clipboard.writeText(td.parentNode.cells[0].children[0].innerText);
//   flash("Details copied to clipboard");
// })));

//Evergreen solution if above is not working, use this
// document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("mouseleave", (() => {
//    td.children[0]?.remove(); //new way of removing popup, 26/4/2025
// })));

//special pop-up for sections menu
let elem=document.getElementById("bottommenu")
elem.onmouseover = function() { document.getElementById("menu").style.display = "block"; }
elem.onclick = function() { document.getElementById("menu").style.display = "none"; }
elem.onmouseout = function() { document.getElementById("menu").style.display = "none"; }
//################End of popup box##########################

//############## Copy SQL text to clibboard on double click ########################
document.querySelectorAll("#tblsess tr td:nth-child(6) , #tblstmnt tr td:nth-child(2)").forEach(td => td.addEventListener("dblclick", (() => {
  if (td.title){
  navigator.clipboard.writeText(td.title).then(() => {  
    flash("SQL text is copied to clipboard");
   });
}
})));

//################ End of Expand box for query string ###############

//Index analysis
function checkindex(){
tab=document.getElementById("IndInfo")
tab.caption.innerHTML="<span>Indexes</span> in '" + obj.dbts.f1 + "' DB" 
trs=tab.rows;
for (let tr of trs) {
  if(tr.cells[5].innerText == 0) {tr.cells[5].classList.add("warn"); tr.cells[5].title="Unused Index"}
  tr.cells[6].title=bytesToSize(Number(tr.cells[6].innerText));
  if(tr.cells[6].innerText > 2000000000) tr.cells[6].classList.add("lime");
  if(tr.cells[7].innerText > 262144 && tr.cells[7].innerText/tr.cells[5].innerText > 50 ) {
    if (tr.cells[5].innerText > 0 ){
     tr.cells[7].title="Each Index scan had to fetch " + Math.round(tr.cells[7].innerText/tr.cells[5].innerText) + " pages on average. Expensive Index";
    }else tr.cells[7].title="Unused indexes. But causing fetches without any benefit"; 
    //(" + bytesToSize(Math.round(tr.cells[6].innerText*8192 / obj.dbts.f4)) + "/day)
    tr.cells[7].classList.add("warn");
    if (tr.cells[8].innerText < 50 ){tr.cells[8].classList.add("warn");tr.cells[8].title="Poor Cache Hit";}
    else if (tr.cells[8].innerText < 80 ) {tr.cells[8].classList.add("lime");tr.cells[8].title="Indexes with less cache hit can cause considerable I/O"; }
  }
}
}

//database time draw graph
function checkdbtime(){
tab=document.getElementById("tableConten")
tab.caption.innerHTML="<span>DB Server Time</span> - Wait-events, CPU time and Delays (<a href="+docurl+"waitevents.html>Reference</a>)"
trs=tab.rows;
let tempstr=""
if (trs.length > 1){ 
  maxevnt=Number(trs[1].cells[1].innerText);
  for (let tr of trs) {
   evnts=tr.cells[1];
   if (evnts.innerText*1500/maxevnt > 1){ evnts.innerHTML += "<div class=bar></div>"; evnts.children[0].style.width = (evnts.innerText*1500/maxevnt).toFixed(1) + "px"; }
   if (tr.cells[0].innerText == "CPU" && tr.cells[1].innerText > 100)   tempstr = "CPU usage is equivalent to " + (evnts.innerText*1.2/2000).toFixed(1) + " CPU cores (approx). "
  }
  //Add footer to table with available info.
  el=document.createElement("tfoot");
  el.innerHTML = "<th colspan='2'>"+ tempstr +" </th>";
  tab.appendChild(el);
}else {
  tab.tBodies[0].innerHTML="No Wait Event information or CPU usage information is available, Probably the PostgreSQL is completely idle or data collection failed"
}
}

//Session information.
function checksess(){
tab=document.getElementById("tblsess")
tab.caption.innerHTML="<span>Sessions</span>"
trs=tab.rows;
for (let tr of trs){
 //column references
 pid=tr.cells[0]; sql=tr.cells[5]; xidage=tr.cells[8]; stime=tr.cells[10];
 if(xidage.innerText > 20) xidage.classList.add("warn");
 //if pid exists in blockers list and victims list
 if (blokers.indexOf(Number(pid.innerText)) > -1){ pid.classList.add("high"); pid.title="Blocker"; 
   tr.cells[1].innerText = updateJson( tr.cells[1].innerText , "f6", "Blocker")
 };
 if (blkvictims.indexOf(Number(pid.innerText)) > -1) { 
   pid.classList.add("warn"); 
   tr.cells[1].innerText = updateJson( tr.cells[1].innerText , "f6", "Victim of Blocker: " + obj.victims.find(el => el.f1 == pid.innerText).f2.toString())
  };
  if(DurationtoSeconds(stime.innerText) > 300 && tr.cells[7].innerText.length > 3) stime.classList.add("warn");
 //if query text is more than 100 chars, copy that to title and trim the query string to 100
 if (sql.innerText.length > 100 && !sql.innerText.startsWith("**") ){ 
  sql.title = sql.innerText; 
  sql.innerText = sql.innerText.substring(0, 100); 
 };
}}

function checkstmnts(){
//if there is no info from pg_stat_statements
let tab= document.getElementById("tblstmnt");
tab.caption.innerHTML = "<span>Top Statements</span> Ranked from high to low impact"
blksize=obj.params.f4;
let hwsql=0,hwbool=0;
if(tab.rows.length < 2) 
 tab.tBodies[0].innerHTML="No pg_stat_statements or pg_stat_monitor info found" //if there is nothing in the table, remove the table
else{
 trs=tab.rows;
 for (let tr of trs){
 sql=tr.cells[1];
 hwbool=0;
 if (sql.innerText.length > 10 ){ sql.title = sql.innerText; sql.innerText = sql.innerText.substring(0, 100); }
 let cel=tr.cells[2]; //SQL workload column. If it is more than 10% highlight accordingly
 if ( cel.innerText > 10) cel.classList.add("lime");
 cel=tr.cells[4]; //statement execution time
 if ( cel.innerText > 60000 ){ cel.classList.add("warn"); hwbool++; } // if statement execution time is more than 1 minute
 else if ( cel.innerText > 10000 ) cel.classList.add("lime"); // if statement execution time is more than 10 seconds  
 cel=tr.cells[6]; //Cache hit column. If cache it is poor highlight accordingly
 if ( cel.innerText.trim() != "" && cel.innerText < 50) cel.classList.add("warn"); // else if (cel.innerText < 90) cel.classList.add("lime");
 [5,7,8,9,10].forEach(function(num){ 
  cel=tr.cells[num]; 
  cel.title = bytesToSize(Number(cel.innerText*blksize));
  if (cel.innerText > 12800){ cel.classList.add("warn"); hwbool++; }    //if more than 100MB
  else if (cel.innerText > 4096) cel.classList.add("lime"); //if more than 32MB
 });
 if (hwbool > 0) hwsql++;
}
setTitles(trs[0],["Weighted Dense Ranking. 1 has the highest impact","SQL Statement","SQL workload / Total workload %","Number of execution of the statement",
"Avg. execution time of the statement (ms)","Average Reads (Blocks)","Cache Hit %","Avg. Dirtied Pages","Avg. Written Pages","Avg. Temp Pages Read","Avg. Temp Pages Written"]);
if (hwsql > 0) strfind += "<li><b>"+ hwsql +" High impact SQL statements found.</b> Please refer <a href=#tblstmnt>Top Statements</a> section for details. Consider optimizing them</li>";
}}


//Checkpointer and bgwriter info
function checkchkpntbgwrtr(){
tab=document.getElementById("tblchkpnt")
tab.caption.innerHTML="<span>BGWriter & Checkpointer</span>"
trs=tab.rows;
setTitles(trs[0],["Forced Checkpoint; Checkpoint triggered by xlog/wal; Need to adjust the max_wal_size","Average Minutes between Checkpoints","Average Write time of a checkpoint",
"Average Disk sync time of a checkpoint","","","","","","","","Dirty buffers cleaned by Checkpointer","Dirty buffers cleaned by BGWriter","Dirty buffers cleaned by Session backends",
"Percentage of bgwriter runs results in a halt","Percentage of bgwriter halts are due to hitting on bgwriter_lru_maxpages limit","Number of days before stats have been reset"]);
if (trs.length > 1){
  tr=trs[1]
  if (tr.cells[0].innerText > 10){
    tr.cells[0].classList.add("high"); tr.cells[0].title="More than 10% of forced checkpoints is not desirable, increase max_wal_size";
  }
  if(tr.cells[1].innerText < 10 ){
    tr.cells[1].classList.add("high"); tr.cells[1].title="checkpoints are too frequent. consider checkpoint_timeout=1800";
  }
  if(tr.cells[11].innerText > 50){
    tr.cells[11].classList.add("high"); tr.cells[11].title="Checkpointer is taking high load of cleaning dirty buffers";
  }
  if(tr.cells[13].innerText > tr.cells[12].innerText){   //if Backends cleans more pages than BgWriter, we have a problem to address
    tr.cells[12].classList.add("high"); tr.cells[12].title="Bgwriter should be cleaning more pages than backends.";
    if (tr.cells[13].innerText > 30){ tr.cells[13].classList.add("high"); tr.cells[13].title="too many dirty pages cleaned by backends"; 
    strfind += "<li>High <b>memory pressure</b>. Consider increasing RAM and shared_buffers</li>"; }   //add to findings
    if(tr.cells[12].innerText < 20){  //if BgWriter cleans less than 20% dirty pages, we should consider to make it more aggressive.
      tr.cells[12].classList.add("high"); tr.cells[12].title+="Bgwriter is not efficient";
      if(tr.cells[14].innerText > 30){
        tr.cells[14].classList.add("high"); tr.cells[14].title="bgwriter could run more frequently. reduce bgwriter_delay";
      }
      if(tr.cells[15].innerText > 10){
        let param = params.find(p => p.param === "bgwriter_lru_maxpages");
        param["suggest"] = Math.ceil((parseInt(param["val"]) + tr.cells[15].innerText/15*100)/100)*100; //calculate new parameter value and suggest
        evalParam("bgwriter_lru_maxpages");
        tr.cells[15].classList.add("high"); tr.cells[15].title="bgwriter halts too frequently. increase bgwriter_lru_maxpages";
      }
    }
  }
  if (tr.cells[16].innerText.trim() == "" || tr.cells[16].innerText < 1 ){ //if "Reset days" is empty or less than a day
    tr.cells[16].classList.add("high"); tr.cells[16].title="sufficient bgwriter stats are not available";
    document.getElementById("tblchkpnt").classList.add("high");
    document.getElementById("tblchkpnt").title = "Sufficient bgwriter stats are not available. This could happen if data is collected immediately after the stats reset or a crash. At least one day of stats are required to do meaningful calculations";
  }
  if( tr.cells[16].innerText > 45 ){ //if "Reset days" is more than 45 days.
    tr.cells[16].classList.add("high"); tr.cells[16].title="Statistics of long-term avarage won't be helpful. Please consider resetting. 1 week is ideal";
  }
}}

function checkiostat(){
tab=document.getElementById("tbliostat")
tab.caption.innerHTML="<span>IO Statistics</span>"
if (tab.rows.length > 1){
}else  tab.tBodies[0].innerHTML="IO statistics is available for PostgreSQL 16 and above"
}


//Check Replication status
function checkreplstat(){
tab=document.getElementById("tblreplstat")
tab.caption.innerHTML="<span>Replication</span>"
let strReps = 0;
let param = params.find(p => p.param === "hot_standby_feedback");
if (typeof param === "undefined") param = {};
if (tab.rows.length > 1){
  for(var i=1;i<tab.rows.length;i++){
    row=tab.rows[i];
    if (row.cells[3].innerText == "streaming") strReps++;
    [4,5,6,7,16,17].forEach(function(num){ cell=row.cells[num]; cell.title=bytesToSize(Number(cell.innerText),1024); 
     if(cell.innerText > 104857600){
      cell.classList.add("warn");
     }else{
      cell.classList.add("lime");
     }
    });
    //xmin age check
    [14,15].forEach(function(num){  if(row.cells[num].innerText > 20) row.cells[num].classList.add("warn"); });
    //check for abandoned replication slots
    if (row.cells[13].innerText == "f" || row.cells[2].innerText == "") {
      row.cells[8].classList.add("high");
      row.cells[8].title="Abandoned replication slot";
      document.getElementById("finditem").innerHTML += "<li> Abandoned replication slot : <b>" +  row.cells[8].innerText + "</b> found. This can cause unwanted WAL retention" ;
    }
  }
  if (strReps > 0  && param["val"] == "off" ){ strfind += "<li>Streaming replication(s) found. However, <b>hot_standby_feedback is off</b>. High chance of query cancellation at standby</li>"; 
    param["suggest"] = "on";
  }
}else{
  tab.tBodies[0].innerHTML="No Replication data found"
  if (!obj.primary && param["val"] == "off" ) strfind += "<li><b>hot_standby_feedback is off</b>. High chance of query cancellation at standby</li></li>";
}
}


//Press Alt_i to go to topics
document.onkeyup = function(e) {
  if (e.altKey && e.which === 73) document.getElementById("topics").scrollIntoView({behavior: "smooth"});
  //       e.preventDefault();
}
</script>
</html>
